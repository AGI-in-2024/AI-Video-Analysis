{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T23:37:35.265406Z",
     "start_time": "2024-09-28T23:37:16.378775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    \"\"\"\n",
    "    Extract audio from a video file and save it as a WAV file.\n",
    "    \"\"\"\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(audio_path, codec='pcm_s16le')  # Save as PCM WAV\n",
    "    video.close()\n",
    "\n",
    "def classify_audio_chunks(audio_path, chunk_duration=10, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Classify 10-second chunks of the audio for emotions.\n",
    "    Returns a dictionary with start time as key and a tuple (predicted emotion, confidence) as value.\n",
    "    If confidence is below the threshold, the predicted emotion will be 'unknown'.\n",
    "    \"\"\"\n",
    "    # Load the model and feature extractor\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "    model = HubertForSequenceClassification.from_pretrained(\"xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned\")\n",
    "    \n",
    "    # Define emotion mapping\n",
    "    num2emotion = {0: 'neutral', 1: 'angry', 2: 'positive', 3: 'sad', 4: 'other'}\n",
    "    \n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sample_rate != 16000:  # Model expects 16kHz\n",
    "        transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = transform(waveform)\n",
    "\n",
    "    # Ensure the audio input is mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)  # Convert to mono by averaging channels\n",
    "    \n",
    "    # Initialize the results dictionary\n",
    "    results = {}\n",
    "\n",
    "    # Calculate number of chunks\n",
    "    total_length = waveform.size(1) / 16000  # Total length in seconds\n",
    "    num_chunks = int(total_length // chunk_duration)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start_time = i * chunk_duration\n",
    "        end_time = start_time + chunk_duration\n",
    "\n",
    "        # Extract the chunk\n",
    "        start_sample = int(start_time * 16000)\n",
    "        end_sample = int(end_time * 16000)\n",
    "        audio_chunk = waveform[:, start_sample:end_sample]\n",
    "\n",
    "        # Prepare inputs for the model\n",
    "        inputs = feature_extractor(\n",
    "            audio_chunk.squeeze(0),  # Remove the channel dimension\n",
    "            sampling_rate=feature_extractor.sampling_rate,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=16000 * chunk_duration,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs['input_values']).logits\n",
    "        \n",
    "        # Get the predicted class index and confidence scores\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        confidence_scores = torch.softmax(logits, dim=-1)  # Get confidence scores\n",
    "        confidence = confidence_scores[0][predicted_class].item()  # Confidence for the predicted class\n",
    "        \n",
    "        # Map the predicted class to emotion, or set to 'unknown' if below threshold\n",
    "        if confidence >= confidence_threshold:\n",
    "            predicted_emotion = num2emotion[predicted_class]\n",
    "        else:\n",
    "            predicted_emotion = 'unknown'\n",
    "        \n",
    "        # Store the result with confidence\n",
    "        results[start_time] = (predicted_emotion, confidence)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example Usage\n",
    "# video_path = \"/home/pe51k/PycharmProjects/secret-repo/data/video/test/test_0.mp4\"\n",
    "video_path = \"/home/pe51k/PycharmProjects/secret-repo/data/video/test/Над расследованием по Северным потокам смеется вся Европа. Великий перепост [TubeRipper.com].mp4\"\n",
    "# video_path = \"/home/pe51k/PycharmProjects/secret-repo/data/video/test/ПОЛОСА ПРЕПЯТСТВИЙ ДЛЯ КОТА АБРИКОСА - Кусь-шоу Весёлые челленджи [TubeRipper.com].mp4\"\n",
    "audio_path = \"extracted_audio.wav\"\n",
    "\n",
    "# Step 1: Extract audio from video\n",
    "extract_audio_from_video(video_path, audio_path)\n",
    "\n",
    "# Step 2: Classify audio in chunks\n",
    "confidence_threshold = 0.7  # Set your desired confidence threshold\n",
    "classification_results = classify_audio_chunks(audio_path, confidence_threshold=confidence_threshold)\n",
    "\n",
    "# Output the classification results\n",
    "print(classification_results)"
   ],
   "id": "6cb7256a9146ffa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in extracted_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ('neutral', 0.898531436920166), 10: ('unknown', 0.5047914981842041), 20: ('unknown', 0.6240713000297546), 30: ('unknown', 0.4543779790401459), 40: ('angry', 0.758493185043335), 50: ('angry', 0.7123038172721863), 60: ('unknown', 0.6553771495819092), 70: ('unknown', 0.4523645341396332), 80: ('unknown', 0.616582989692688), 90: ('angry', 0.9587709307670593), 100: ('angry', 0.8447172045707703), 110: ('unknown', 0.6968732476234436), 120: ('unknown', 0.5530036687850952), 130: ('unknown', 0.5075026750564575), 140: ('angry', 0.8949615359306335), 150: ('unknown', 0.5432318449020386), 160: ('unknown', 0.5116928219795227), 170: ('neutral', 0.7228280305862427), 180: ('unknown', 0.6902819275856018), 190: ('unknown', 0.5846384167671204), 200: ('neutral', 0.9654733538627625), 210: ('neutral', 0.981601893901825), 220: ('neutral', 0.7543083429336548), 230: ('angry', 0.8148767948150635)}\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
