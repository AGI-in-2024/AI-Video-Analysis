{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-28T00:51:12.226676Z",
     "start_time": "2024-09-28T00:51:12.107782Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "while os.getcwd().split(os.sep)[-1] != \"secret-repo\":\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "!ls"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data\t     'loss weight.png'\t README.md   venv\r\n",
      " LICENSE.md   notebooks\t\t src\t     weights\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.detection import detect_yolo10\n",
    "\n",
    "with open('data/video/test/test_0.mp4', 'rb') as f:\n",
    "    video_binary = f.read()\n",
    "\n",
    "results = detect_yolo10(video_binary, frequency=10)  # Detect objects every 10th frame\n",
    "\n",
    "# Display detection results\n",
    "for frame_num, detections in results.items():\n",
    "    print(f\"Frame {frame_num}: {detections}\")"
   ],
   "id": "2496f59cd1257069"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T00:53:44.642372Z",
     "start_time": "2024-09-28T00:51:18.446909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.detection import detect_yolo_world\n",
    "\n",
    "with open('data/video/test/test_0.mp4', 'rb') as f:\n",
    "    video_binary = f.read()\n",
    "\n",
    "results = detect_yolo_world(video_binary, class_names=[\"car\", \"plane\"], frequency=10)  # Detect objects every 10th frame\n",
    "\n",
    "# Display detection results\n",
    "for frame_num, detections in results.items():\n",
    "    print(f\"Frame {frame_num}: {detections}\")"
   ],
   "id": "5d59cefc77c4a697",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pe51k/PycharmProjects/secret-repo/venv/lib/python3.11/site-packages/clip/clip.py:61: UserWarning: /home/pe51k/.cache/clip/ViT-B-32.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
      "100%|███████████████████████████████████████| 338M/338M [01:35<00:00, 3.72MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 59.4ms\n",
      "Speed: 4.7ms preprocess, 59.4ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 2.4ms preprocess, 36.4ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 5.2ms preprocess, 34.8ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 6.0ms preprocess, 30.3ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.3ms preprocess, 30.0ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.6ms\n",
      "Speed: 6.7ms preprocess, 37.6ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 3.6ms preprocess, 32.6ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.1ms\n",
      "Speed: 4.4ms preprocess, 30.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 7.0ms preprocess, 32.0ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.5ms preprocess, 39.7ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.6ms\n",
      "Speed: 5.0ms preprocess, 32.6ms inference, 45.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.9ms\n",
      "Speed: 4.7ms preprocess, 27.9ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 4.4ms preprocess, 31.2ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 4.9ms preprocess, 30.9ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.7ms\n",
      "Speed: 4.5ms preprocess, 28.7ms inference, 33.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.9ms\n",
      "Speed: 7.8ms preprocess, 30.9ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.9ms\n",
      "Speed: 4.2ms preprocess, 27.9ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.7ms\n",
      "Speed: 5.3ms preprocess, 39.7ms inference, 32.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.9ms\n",
      "Speed: 5.7ms preprocess, 32.9ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.5ms\n",
      "Speed: 2.1ms preprocess, 30.5ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.1ms\n",
      "Speed: 8.3ms preprocess, 30.1ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.2ms\n",
      "Speed: 5.5ms preprocess, 26.2ms inference, 32.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.5ms\n",
      "Speed: 11.0ms preprocess, 39.5ms inference, 31.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 2.8ms preprocess, 26.6ms inference, 35.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 6.1ms preprocess, 31.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 6.1ms preprocess, 31.3ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 5.2ms preprocess, 31.1ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 2.7ms preprocess, 39.3ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 3.1ms preprocess, 30.0ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.9ms preprocess, 27.0ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 5.3ms preprocess, 34.3ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.5ms\n",
      "Speed: 5.0ms preprocess, 39.5ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 3.0ms preprocess, 32.6ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.7ms preprocess, 31.3ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 7.6ms preprocess, 30.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.7ms\n",
      "Speed: 8.0ms preprocess, 39.7ms inference, 31.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.6ms\n",
      "Speed: 4.8ms preprocess, 29.6ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 23.0ms\n",
      "Speed: 9.1ms preprocess, 23.0ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.7ms\n",
      "Speed: 2.8ms preprocess, 31.7ms inference, 28.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plane, 39.5ms\n",
      "Speed: 3.4ms preprocess, 39.5ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plane, 30.6ms\n",
      "Speed: 4.5ms preprocess, 30.6ms inference, 28.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.8ms\n",
      "Speed: 6.7ms preprocess, 26.8ms inference, 35.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 8.1ms preprocess, 31.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.5ms\n",
      "Speed: 2.2ms preprocess, 31.5ms inference, 27.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.6ms\n",
      "Speed: 2.6ms preprocess, 39.6ms inference, 35.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.8ms\n",
      "Speed: 5.3ms preprocess, 27.8ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.5ms\n",
      "Speed: 2.7ms preprocess, 26.5ms inference, 35.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 4.2ms preprocess, 31.2ms inference, 26.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.3ms preprocess, 29.2ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.3ms\n",
      "Speed: 3.8ms preprocess, 35.3ms inference, 38.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 22.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.7ms\n",
      "Speed: 5.0ms preprocess, 30.7ms inference, 25.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.5ms\n",
      "Speed: 12.1ms preprocess, 28.5ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.8ms\n",
      "Speed: 6.1ms preprocess, 27.8ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.8ms\n",
      "Speed: 3.0ms preprocess, 39.8ms inference, 33.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.9ms\n",
      "Speed: 3.8ms preprocess, 27.9ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 4.0ms preprocess, 28.5ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.7ms\n",
      "Speed: 4.9ms preprocess, 36.7ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plane, 31.4ms\n",
      "Speed: 6.2ms preprocess, 31.4ms inference, 23.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 6.1ms preprocess, 31.3ms inference, 25.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 3.6ms preprocess, 34.5ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 3.5ms preprocess, 31.2ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plane, 22.6ms\n",
      "Speed: 4.4ms preprocess, 22.6ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plane, 39.3ms\n",
      "Speed: 1.4ms preprocess, 39.3ms inference, 34.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.2ms\n",
      "Speed: 6.4ms preprocess, 30.2ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 3.7ms preprocess, 35.2ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 3.3ms preprocess, 36.4ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.9ms\n",
      "Speed: 4.7ms preprocess, 29.9ms inference, 27.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.5ms\n",
      "Speed: 7.1ms preprocess, 26.5ms inference, 39.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.5ms\n",
      "Speed: 1.7ms preprocess, 34.5ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.3ms\n",
      "Speed: 4.4ms preprocess, 26.3ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 36.7ms\n",
      "Speed: 5.9ms preprocess, 36.7ms inference, 36.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.7ms\n",
      "Speed: 6.4ms preprocess, 29.7ms inference, 25.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.0ms\n",
      "Speed: 5.1ms preprocess, 33.0ms inference, 38.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.7ms\n",
      "Speed: 7.0ms preprocess, 30.7ms inference, 22.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.1ms\n",
      "Speed: 3.8ms preprocess, 29.1ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 36.9ms\n",
      "Speed: 2.7ms preprocess, 36.9ms inference, 34.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 3.4ms preprocess, 31.2ms inference, 20.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.4ms\n",
      "Speed: 9.5ms preprocess, 34.4ms inference, 35.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 1.2ms preprocess, 31.1ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 1.1ms preprocess, 31.1ms inference, 26.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.3ms\n",
      "Speed: 6.1ms preprocess, 34.3ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.5ms\n",
      "Speed: 11.7ms preprocess, 37.5ms inference, 33.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.6ms\n",
      "Speed: 4.2ms preprocess, 32.6ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.6ms\n",
      "Speed: 3.2ms preprocess, 30.6ms inference, 31.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.5ms\n",
      "Speed: 1.3ms preprocess, 26.5ms inference, 28.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.4ms\n",
      "Speed: 6.5ms preprocess, 39.4ms inference, 31.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.7ms\n",
      "Speed: 5.0ms preprocess, 33.7ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 39.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 3.8ms preprocess, 31.3ms inference, 32.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 3.7ms preprocess, 27.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.8ms\n",
      "Speed: 6.5ms preprocess, 31.8ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.5ms\n",
      "Speed: 2.3ms preprocess, 30.5ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.4ms\n",
      "Speed: 3.2ms preprocess, 35.4ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.8ms\n",
      "Speed: 6.9ms preprocess, 29.8ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 23.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.0ms\n",
      "Speed: 5.0ms preprocess, 29.0ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 5.1ms preprocess, 31.2ms inference, 32.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.9ms\n",
      "Speed: 7.3ms preprocess, 30.9ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.0ms\n",
      "Speed: 7.9ms preprocess, 34.0ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.4ms\n",
      "Speed: 4.2ms preprocess, 31.4ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.8ms\n",
      "Speed: 3.1ms preprocess, 26.8ms inference, 39.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 27.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 36.8ms\n",
      "Speed: 7.1ms preprocess, 36.8ms inference, 30.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.6ms\n",
      "Speed: 10.4ms preprocess, 27.6ms inference, 27.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.5ms\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 36.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.6ms\n",
      "Speed: 5.9ms preprocess, 27.6ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 3.5ms preprocess, 28.1ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 25.9ms\n",
      "Speed: 5.3ms preprocess, 25.9ms inference, 36.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 8.3ms preprocess, 39.3ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.4ms\n",
      "Speed: 5.7ms preprocess, 31.4ms inference, 27.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.2ms\n",
      "Speed: 7.6ms preprocess, 32.2ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.0ms\n",
      "Speed: 9.4ms preprocess, 32.0ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.8ms\n",
      "Speed: 2.4ms preprocess, 30.8ms inference, 33.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.5ms\n",
      "Speed: 6.1ms preprocess, 37.5ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.2ms\n",
      "Speed: 4.4ms preprocess, 28.2ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 4.2ms preprocess, 34.3ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 6.2ms preprocess, 31.6ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.7ms\n",
      "Speed: 8.9ms preprocess, 39.7ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 3.1ms preprocess, 31.1ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 4.0ms preprocess, 30.8ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.2ms\n",
      "Speed: 3.8ms preprocess, 31.2ms inference, 26.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.4ms\n",
      "Speed: 8.1ms preprocess, 29.4ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 25.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 39.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 6.1ms preprocess, 31.2ms inference, 29.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 7.1ms preprocess, 31.2ms inference, 26.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 30.2ms\n",
      "Speed: 5.9ms preprocess, 30.2ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 26.6ms\n",
      "Speed: 4.0ms preprocess, 26.6ms inference, 31.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.0ms\n",
      "Speed: 3.0ms preprocess, 39.0ms inference, 28.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.3ms\n",
      "Speed: 3.3ms preprocess, 31.3ms inference, 22.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.4ms\n",
      "Speed: 8.8ms preprocess, 37.4ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 34.4ms\n",
      "Speed: 1.1ms preprocess, 34.4ms inference, 26.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.4ms\n",
      "Speed: 6.0ms preprocess, 26.4ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.0ms\n",
      "Speed: 5.3ms preprocess, 31.0ms inference, 30.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 29.4ms\n",
      "Speed: 3.6ms preprocess, 29.4ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 36.7ms\n",
      "Speed: 3.7ms preprocess, 36.7ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.1ms\n",
      "Speed: 3.7ms preprocess, 32.1ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.0ms\n",
      "Speed: 4.3ms preprocess, 33.0ms inference, 39.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 29.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.5ms\n",
      "Speed: 5.6ms preprocess, 31.5ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.3ms\n",
      "Speed: 3.6ms preprocess, 32.3ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 26.7ms\n",
      "Speed: 3.2ms preprocess, 26.7ms inference, 25.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.6ms\n",
      "Speed: 4.6ms preprocess, 39.6ms inference, 31.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.0ms\n",
      "Speed: 6.1ms preprocess, 34.0ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 25.9ms\n",
      "Speed: 6.1ms preprocess, 25.9ms inference, 33.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.5ms\n",
      "Speed: 3.3ms preprocess, 27.5ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.1ms\n",
      "Speed: 3.1ms preprocess, 39.1ms inference, 30.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 32.8ms\n",
      "Speed: 5.3ms preprocess, 32.8ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 33.0ms\n",
      "Speed: 5.1ms preprocess, 33.0ms inference, 39.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 4.6ms preprocess, 31.2ms inference, 26.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.7ms\n",
      "Speed: 4.4ms preprocess, 30.7ms inference, 28.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.6ms\n",
      "Speed: 3.1ms preprocess, 34.6ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.4ms\n",
      "Speed: 7.0ms preprocess, 26.4ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.0ms\n",
      "Speed: 7.3ms preprocess, 39.0ms inference, 32.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.4ms\n",
      "Speed: 3.0ms preprocess, 30.4ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.9ms\n",
      "Speed: 2.8ms preprocess, 32.9ms inference, 38.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.7ms\n",
      "Speed: 3.2ms preprocess, 29.7ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.0ms\n",
      "Speed: 2.1ms preprocess, 26.0ms inference, 37.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 4.1ms preprocess, 31.1ms inference, 25.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.3ms\n",
      "Speed: 5.9ms preprocess, 30.3ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.9ms\n",
      "Speed: 4.0ms preprocess, 34.9ms inference, 32.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.5ms preprocess, 31.4ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.0ms\n",
      "Speed: 2.4ms preprocess, 39.0ms inference, 32.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 26.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.3ms\n",
      "Speed: 4.8ms preprocess, 26.3ms inference, 37.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 7.8ms preprocess, 31.2ms inference, 28.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.8ms\n",
      "Speed: 3.0ms preprocess, 30.8ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 34.5ms\n",
      "Speed: 4.9ms preprocess, 34.5ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 5.0ms preprocess, 31.2ms inference, 21.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.5ms\n",
      "Speed: 6.4ms preprocess, 39.5ms inference, 36.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.3ms\n",
      "Speed: 4.3ms preprocess, 35.3ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.8ms\n",
      "Speed: 4.4ms preprocess, 29.8ms inference, 31.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.0ms\n",
      "Speed: 2.6ms preprocess, 31.0ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.4ms\n",
      "Speed: 4.2ms preprocess, 27.4ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.1ms\n",
      "Speed: 8.6ms preprocess, 39.1ms inference, 28.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.0ms\n",
      "Speed: 5.3ms preprocess, 34.0ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 4.6ms preprocess, 28.3ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 8.3ms preprocess, 31.7ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 32.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.9ms\n",
      "Speed: 3.2ms preprocess, 28.9ms inference, 26.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.1ms\n",
      "Speed: 4.6ms preprocess, 35.1ms inference, 27.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.0ms\n",
      "Speed: 5.4ms preprocess, 34.0ms inference, 25.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 7.2ms preprocess, 26.6ms inference, 35.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.8ms\n",
      "Speed: 6.3ms preprocess, 37.8ms inference, 27.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.6ms\n",
      "Speed: 6.1ms preprocess, 30.6ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 4.8ms preprocess, 26.6ms inference, 31.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.2ms\n",
      "Speed: 5.1ms preprocess, 28.2ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 38.9ms\n",
      "Speed: 6.9ms preprocess, 38.9ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 38.8ms\n",
      "Speed: 2.9ms preprocess, 38.8ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.8ms\n",
      "Speed: 4.7ms preprocess, 28.8ms inference, 29.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.0ms\n",
      "Speed: 5.7ms preprocess, 31.0ms inference, 37.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.4ms\n",
      "Speed: 6.5ms preprocess, 34.4ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 36.6ms\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 20.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.8ms\n",
      "Speed: 7.8ms preprocess, 33.8ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.2ms\n",
      "Speed: 2.1ms preprocess, 28.2ms inference, 27.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 3.7ms preprocess, 31.2ms inference, 36.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 38.1ms\n",
      "Speed: 8.7ms preprocess, 38.1ms inference, 24.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.2ms\n",
      "Speed: 3.9ms preprocess, 26.2ms inference, 29.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 plane, 29.1ms\n",
      "Speed: 1.4ms preprocess, 29.1ms inference, 36.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.6ms\n",
      "Speed: 3.6ms preprocess, 37.6ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.7ms\n",
      "Speed: 2.6ms preprocess, 28.7ms inference, 27.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 25.3ms\n",
      "Speed: 9.4ms preprocess, 25.3ms inference, 38.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.6ms\n",
      "Speed: 6.9ms preprocess, 31.6ms inference, 26.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.6ms\n",
      "Speed: 2.4ms preprocess, 31.6ms inference, 27.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plane, 26.5ms\n",
      "Speed: 4.0ms preprocess, 26.5ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.7ms\n",
      "Speed: 3.9ms preprocess, 39.7ms inference, 25.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.6ms\n",
      "Speed: 3.8ms preprocess, 39.6ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 3.7ms preprocess, 28.1ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 35.3ms\n",
      "Speed: 4.5ms preprocess, 35.3ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.4ms\n",
      "Speed: 3.6ms preprocess, 30.4ms inference, 31.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 38.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.1ms\n",
      "Speed: 2.9ms preprocess, 31.1ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 29.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.5ms\n",
      "Speed: 4.2ms preprocess, 26.5ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.3ms\n",
      "Speed: 3.5ms preprocess, 29.3ms inference, 38.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.3ms\n",
      "Speed: 2.6ms preprocess, 31.3ms inference, 36.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.6ms\n",
      "Speed: 4.7ms preprocess, 32.6ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 36.0ms\n",
      "Speed: 1.7ms preprocess, 36.0ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.6ms\n",
      "Speed: 11.4ms preprocess, 30.6ms inference, 25.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 37.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 35.4ms\n",
      "Speed: 2.6ms preprocess, 35.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.6ms\n",
      "Speed: 4.6ms preprocess, 31.6ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 4.5ms preprocess, 26.2ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.0ms\n",
      "Speed: 4.8ms preprocess, 36.0ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.3ms\n",
      "Speed: 3.8ms preprocess, 37.3ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 4.3ms preprocess, 33.4ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.5ms\n",
      "Speed: 4.1ms preprocess, 35.5ms inference, 35.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 36.5ms\n",
      "Speed: 5.1ms preprocess, 36.5ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.5ms\n",
      "Speed: 3.8ms preprocess, 30.5ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.9ms\n",
      "Speed: 4.6ms preprocess, 27.9ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 5.9ms preprocess, 26.3ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.2ms preprocess, 26.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 8.2ms preprocess, 33.4ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.4ms\n",
      "Speed: 3.1ms preprocess, 37.4ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 4.6ms preprocess, 29.3ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 5.9ms preprocess, 26.2ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 27.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.9ms\n",
      "Speed: 1.2ms preprocess, 33.9ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.4ms\n",
      "Speed: 4.9ms preprocess, 26.4ms inference, 37.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.3ms\n",
      "Speed: 1.4ms preprocess, 33.3ms inference, 37.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 6.5ms preprocess, 31.2ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.4ms\n",
      "Speed: 6.0ms preprocess, 26.4ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.6ms\n",
      "Speed: 5.8ms preprocess, 28.6ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.0ms\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.3ms\n",
      "Speed: 4.6ms preprocess, 35.3ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.4ms\n",
      "Speed: 1.4ms preprocess, 31.4ms inference, 26.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.2ms\n",
      "Speed: 5.6ms preprocess, 27.2ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 26.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.3ms\n",
      "Speed: 3.0ms preprocess, 37.3ms inference, 35.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.3ms\n",
      "Speed: 6.1ms preprocess, 30.3ms inference, 28.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.1ms\n",
      "Speed: 1.8ms preprocess, 30.1ms inference, 26.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.5ms\n",
      "Speed: 4.0ms preprocess, 31.5ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 3.9ms preprocess, 31.3ms inference, 27.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.6ms\n",
      "Speed: 4.4ms preprocess, 39.6ms inference, 35.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.4ms\n",
      "Speed: 6.1ms preprocess, 27.4ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 3.8ms preprocess, 26.6ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.0ms\n",
      "Speed: 3.4ms preprocess, 31.0ms inference, 26.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.0ms\n",
      "Speed: 3.4ms preprocess, 28.0ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 38.7ms\n",
      "Speed: 6.3ms preprocess, 38.7ms inference, 32.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 23.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.0ms\n",
      "Speed: 4.8ms preprocess, 33.0ms inference, 39.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 6.6ms preprocess, 31.3ms inference, 25.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 1.9ms preprocess, 31.1ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.1ms\n",
      "Speed: 8.2ms preprocess, 34.1ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.4ms\n",
      "Speed: 3.6ms preprocess, 26.4ms inference, 30.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.4ms\n",
      "Speed: 6.5ms preprocess, 39.4ms inference, 33.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.1ms\n",
      "Speed: 2.9ms preprocess, 29.1ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 5.7ms preprocess, 26.6ms inference, 35.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.8ms\n",
      "Speed: 4.3ms preprocess, 26.8ms inference, 38.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.1ms\n",
      "Speed: 9.2ms preprocess, 37.1ms inference, 30.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.6ms\n",
      "Speed: 4.7ms preprocess, 30.6ms inference, 25.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.5ms\n",
      "Speed: 5.8ms preprocess, 39.5ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.0ms\n",
      "Speed: 2.3ms preprocess, 30.0ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.1ms\n",
      "Speed: 6.4ms preprocess, 26.1ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 6.7ms preprocess, 31.1ms inference, 22.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.8ms\n",
      "Speed: 7.9ms preprocess, 30.8ms inference, 24.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 4.0ms preprocess, 34.4ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 4.7ms preprocess, 31.3ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 22.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 39.7ms\n",
      "Speed: 8.7ms preprocess, 39.7ms inference, 33.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.8ms\n",
      "Speed: 5.6ms preprocess, 27.8ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 28.9ms\n",
      "Speed: 1.3ms preprocess, 28.9ms inference, 39.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.0ms\n",
      "Speed: 8.1ms preprocess, 31.0ms inference, 23.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.3ms\n",
      "Speed: 2.3ms preprocess, 30.3ms inference, 26.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 32.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 26.1ms\n",
      "Speed: 7.1ms preprocess, 26.1ms inference, 37.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.9ms\n",
      "Speed: 7.4ms preprocess, 30.9ms inference, 25.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 28.4ms\n",
      "Speed: 3.5ms preprocess, 28.4ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 37.1ms\n",
      "Speed: 4.4ms preprocess, 37.1ms inference, 34.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 31.2ms\n",
      "Speed: 4.8ms preprocess, 31.2ms inference, 23.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 28.9ms\n",
      "Speed: 5.3ms preprocess, 28.9ms inference, 39.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 31.3ms\n",
      "Speed: 6.4ms preprocess, 31.3ms inference, 27.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 32.0ms\n",
      "Speed: 3.4ms preprocess, 32.0ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 36.9ms\n",
      "Speed: 5.1ms preprocess, 36.9ms inference, 32.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 29.0ms\n",
      "Speed: 4.6ms preprocess, 29.0ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 26.8ms\n",
      "Speed: 5.0ms preprocess, 26.8ms inference, 39.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 28.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 28.1ms\n",
      "Speed: 3.9ms preprocess, 28.1ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 39.0ms\n",
      "Speed: 7.4ms preprocess, 39.0ms inference, 32.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.6ms\n",
      "Speed: 2.9ms preprocess, 29.6ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.5ms\n",
      "Speed: 2.2ms preprocess, 26.5ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.5ms\n",
      "Speed: 2.5ms preprocess, 32.5ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.6ms\n",
      "Speed: 2.4ms preprocess, 26.6ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.1ms\n",
      "Speed: 3.2ms preprocess, 39.1ms inference, 32.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.6ms\n",
      "Speed: 3.9ms preprocess, 32.6ms inference, 26.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 33.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.3ms\n",
      "Speed: 6.1ms preprocess, 32.3ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.6ms\n",
      "Speed: 4.3ms preprocess, 26.6ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.5ms\n",
      "Speed: 2.7ms preprocess, 39.5ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 4.2ms preprocess, 31.2ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 28.5ms\n",
      "Speed: 6.5ms preprocess, 28.5ms inference, 25.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 37.4ms\n",
      "Speed: 4.1ms preprocess, 37.4ms inference, 37.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 33.2ms\n",
      "Speed: 2.6ms preprocess, 33.2ms inference, 30.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.1ms\n",
      "Speed: 3.7ms preprocess, 31.1ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.5ms\n",
      "Speed: 6.3ms preprocess, 29.5ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 28.5ms\n",
      "Speed: 4.7ms preprocess, 28.5ms inference, 27.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 37.5ms\n",
      "Speed: 5.6ms preprocess, 37.5ms inference, 33.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 34.2ms\n",
      "Speed: 3.9ms preprocess, 34.2ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.4ms\n",
      "Speed: 3.6ms preprocess, 30.4ms inference, 25.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.4ms\n",
      "Speed: 2.8ms preprocess, 29.4ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.7ms\n",
      "Speed: 6.4ms preprocess, 26.7ms inference, 32.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.5ms\n",
      "Speed: 7.1ms preprocess, 39.5ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.9ms\n",
      "Speed: 4.6ms preprocess, 31.9ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 28.3ms\n",
      "Speed: 6.5ms preprocess, 28.3ms inference, 31.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 28.8ms\n",
      "Speed: 3.8ms preprocess, 28.8ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 32.1ms\n",
      "Speed: 4.3ms preprocess, 32.1ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 36.8ms\n",
      "Speed: 8.3ms preprocess, 36.8ms inference, 27.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 3.6ms preprocess, 30.9ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.6ms\n",
      "Speed: 1.1ms preprocess, 39.6ms inference, 31.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 32.2ms\n",
      "Speed: 4.0ms preprocess, 32.2ms inference, 26.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.0ms\n",
      "Speed: 6.1ms preprocess, 27.0ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 27.5ms\n",
      "Speed: 2.3ms preprocess, 27.5ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 38.8ms\n",
      "Speed: 2.9ms preprocess, 38.8ms inference, 29.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.8ms\n",
      "Speed: 4.4ms preprocess, 30.8ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.9ms\n",
      "Speed: 4.8ms preprocess, 34.9ms inference, 33.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 33.0ms\n",
      "Speed: 5.8ms preprocess, 33.0ms inference, 25.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.1ms\n",
      "Speed: 6.1ms preprocess, 28.1ms inference, 32.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.0ms\n",
      "Speed: 5.4ms preprocess, 31.0ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.4ms\n",
      "Speed: 5.3ms preprocess, 28.4ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.3ms\n",
      "Speed: 5.1ms preprocess, 39.3ms inference, 30.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.9ms\n",
      "Speed: 3.5ms preprocess, 30.9ms inference, 24.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.0ms\n",
      "Speed: 5.0ms preprocess, 29.0ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 5.6ms preprocess, 31.2ms inference, 28.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.3ms\n",
      "Speed: 5.2ms preprocess, 30.3ms inference, 28.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.3ms\n",
      "Speed: 2.7ms preprocess, 34.3ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 25.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.8ms preprocess, 39.7ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.4ms\n",
      "Speed: 5.6ms preprocess, 29.4ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 7.1ms preprocess, 31.2ms inference, 23.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.4ms\n",
      "Speed: 5.2ms preprocess, 31.4ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 26.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.8ms\n",
      "Speed: 7.1ms preprocess, 31.8ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 4.8ms preprocess, 28.3ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.1ms preprocess, 30.6ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 39.5ms\n",
      "Speed: 4.1ms preprocess, 39.5ms inference, 34.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.7ms\n",
      "Speed: 4.4ms preprocess, 27.7ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.8ms\n",
      "Speed: 3.5ms preprocess, 26.8ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.4ms\n",
      "Speed: 5.6ms preprocess, 31.4ms inference, 25.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.9ms\n",
      "Speed: 4.1ms preprocess, 29.9ms inference, 28.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.1ms\n",
      "Speed: 6.1ms preprocess, 39.1ms inference, 29.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.8ms\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.4ms\n",
      "Speed: 3.4ms preprocess, 31.4ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.7ms\n",
      "Speed: 2.2ms preprocess, 29.7ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.1ms\n",
      "Speed: 5.8ms preprocess, 39.1ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.3ms\n",
      "Speed: 8.0ms preprocess, 31.3ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 37.5ms\n",
      "Speed: 6.1ms preprocess, 37.5ms inference, 36.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 31.7ms\n",
      "Speed: 3.3ms preprocess, 31.7ms inference, 28.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 28.5ms\n",
      "Speed: 5.9ms preprocess, 28.5ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 28.1ms\n",
      "Speed: 8.4ms preprocess, 28.1ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 29.9ms\n",
      "Speed: 6.0ms preprocess, 29.9ms inference, 23.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 plane, 35.0ms\n",
      "Speed: 4.5ms preprocess, 35.0ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.7ms\n",
      "Speed: 5.9ms preprocess, 29.7ms inference, 27.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 39.5ms\n",
      "Speed: 4.6ms preprocess, 39.5ms inference, 33.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 30.8ms\n",
      "Speed: 8.4ms preprocess, 30.8ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 26.4ms\n",
      "Speed: 6.4ms preprocess, 26.4ms inference, 39.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 27.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.5ms\n",
      "Speed: 3.9ms preprocess, 29.5ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 34.5ms\n",
      "Speed: 3.4ms preprocess, 34.5ms inference, 34.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 23.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 29.0ms\n",
      "Speed: 5.5ms preprocess, 29.0ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 4.5ms preprocess, 31.3ms inference, 25.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 28.1ms\n",
      "Speed: 2.1ms preprocess, 28.1ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 36.6ms\n",
      "Speed: 6.9ms preprocess, 36.6ms inference, 32.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 1.3ms preprocess, 31.3ms inference, 21.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.5ms\n",
      "Speed: 5.6ms preprocess, 35.5ms inference, 38.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.3ms\n",
      "Speed: 4.3ms preprocess, 31.3ms inference, 26.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.1ms\n",
      "Speed: 3.0ms preprocess, 31.1ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 35.1ms\n",
      "Speed: 7.5ms preprocess, 35.1ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.2ms\n",
      "Speed: 2.8ms preprocess, 31.2ms inference, 23.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 25.8ms\n",
      "Speed: 1.3ms preprocess, 25.8ms inference, 39.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 31.4ms\n",
      "Speed: 2.8ms preprocess, 31.4ms inference, 30.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 0: []\n",
      "Frame 10: []\n",
      "Frame 20: []\n",
      "Frame 30: []\n",
      "Frame 40: []\n",
      "Frame 50: []\n",
      "Frame 60: []\n",
      "Frame 70: []\n",
      "Frame 80: []\n",
      "Frame 90: []\n",
      "Frame 100: [{'class': 'car', 'confidence': 0.45161107182502747, 'coordinates': [604.96484375, 227.2288360595703, 761.029296875, 368.57037353515625]}]\n",
      "Frame 110: [{'class': 'car', 'confidence': 0.2925072908401489, 'coordinates': [597.0692138671875, 226.84547424316406, 767.8201904296875, 382.01513671875]}]\n",
      "Frame 120: []\n",
      "Frame 130: []\n",
      "Frame 140: [{'class': 'car', 'confidence': 0.3174857795238495, 'coordinates': [551.3748779296875, 214.40870666503906, 791.7708740234375, 431.5194091796875]}]\n",
      "Frame 150: [{'class': 'car', 'confidence': 0.4465472400188446, 'coordinates': [530.2697143554688, 246.099609375, 804.0625610351562, 452.6009521484375]}]\n",
      "Frame 160: [{'class': 'car', 'confidence': 0.6526302099227905, 'coordinates': [502.4998779296875, 205.49217224121094, 819.6390380859375, 472.42724609375]}]\n",
      "Frame 170: [{'class': 'car', 'confidence': 0.6906045079231262, 'coordinates': [467.3199462890625, 196.460693359375, 840.7440185546875, 536.2745361328125]}]\n",
      "Frame 180: [{'class': 'car', 'confidence': 0.6586465239524841, 'coordinates': [435.11199951171875, 183.367919921875, 873.4196166992188, 567.3634643554688]}]\n",
      "Frame 190: [{'class': 'car', 'confidence': 0.7420434951782227, 'coordinates': [403.649658203125, 171.94671630859375, 907.5111083984375, 617.9774169921875]}]\n",
      "Frame 200: [{'class': 'car', 'confidence': 0.8829783797264099, 'coordinates': [374.3396301269531, 163.51934814453125, 939.744384765625, 670.9139404296875]}]\n",
      "Frame 210: [{'class': 'car', 'confidence': 0.8611555099487305, 'coordinates': [347.6455078125, 159.25079345703125, 963.398193359375, 704.6371459960938]}]\n",
      "Frame 220: [{'class': 'car', 'confidence': 0.880788266658783, 'coordinates': [330.97906494140625, 159.46527099609375, 969.0626831054688, 716.4658203125]}]\n",
      "Frame 230: [{'class': 'car', 'confidence': 0.8766475319862366, 'coordinates': [326.0931396484375, 159.44482421875, 961.810791015625, 718.9684448242188]}]\n",
      "Frame 240: [{'class': 'car', 'confidence': 0.6400639414787292, 'coordinates': [323.64886474609375, 158.24249267578125, 950.6887817382812, 672.7461547851562]}]\n",
      "Frame 250: []\n",
      "Frame 260: []\n",
      "Frame 270: []\n",
      "Frame 280: []\n",
      "Frame 290: []\n",
      "Frame 300: []\n",
      "Frame 310: []\n",
      "Frame 320: []\n",
      "Frame 330: []\n",
      "Frame 340: []\n",
      "Frame 350: []\n",
      "Frame 360: [{'class': 'car', 'confidence': 0.4164624512195587, 'coordinates': [638.2232666015625, 314.68865966796875, 849.0865478515625, 432.71417236328125]}]\n",
      "Frame 370: [{'class': 'car', 'confidence': 0.5350668430328369, 'coordinates': [601.0540771484375, 306.774169921875, 831.958251953125, 465.283935546875]}]\n",
      "Frame 380: [{'class': 'car', 'confidence': 0.7425477504730225, 'coordinates': [594.2682495117188, 296.059814453125, 834.7048950195312, 462.803955078125]}]\n",
      "Frame 390: [{'class': 'car', 'confidence': 0.5500404834747314, 'coordinates': [539.889404296875, 282.703369140625, 787.495361328125, 464.2747802734375]}]\n",
      "Frame 400: [{'class': 'car', 'confidence': 0.4624350965023041, 'coordinates': [469.2843322753906, 279.63775634765625, 887.4049072265625, 500.92755126953125]}]\n",
      "Frame 410: [{'class': 'plane', 'confidence': 0.4866066873073578, 'coordinates': [417.5455322265625, 287.391845703125, 892.4228515625, 488.37933349609375]}]\n",
      "Frame 420: [{'class': 'plane', 'confidence': 0.5313789248466492, 'coordinates': [364.1927490234375, 286.21209716796875, 875.1527099609375, 503.5618896484375]}]\n",
      "Frame 430: [{'class': 'car', 'confidence': 0.6479026675224304, 'coordinates': [355.5364990234375, 286.00616455078125, 837.8968505859375, 497.757568359375]}]\n",
      "Frame 440: []\n",
      "Frame 450: [{'class': 'car', 'confidence': 0.5920864939689636, 'coordinates': [284.2947998046875, 300.26739501953125, 774.7177734375, 503.615234375]}]\n",
      "Frame 460: [{'class': 'car', 'confidence': 0.8407206535339355, 'coordinates': [286.9615478515625, 297.63726806640625, 766.9952392578125, 477.90447998046875]}]\n",
      "Frame 470: [{'class': 'car', 'confidence': 0.7818753719329834, 'coordinates': [297.934326171875, 288.5029296875, 766.689697265625, 476.33087158203125]}]\n",
      "Frame 480: [{'class': 'car', 'confidence': 0.6809776425361633, 'coordinates': [320.9979248046875, 285.27203369140625, 776.37548828125, 471.06341552734375]}]\n",
      "Frame 490: [{'class': 'car', 'confidence': 0.2959153652191162, 'coordinates': [362.527099609375, 287.14483642578125, 801.8525390625, 464.92291259765625]}]\n",
      "Frame 500: []\n",
      "Frame 510: [{'class': 'car', 'confidence': 0.6293891668319702, 'coordinates': [449.4079895019531, 277.664306640625, 856.116943359375, 468.831787109375]}]\n",
      "Frame 520: [{'class': 'car', 'confidence': 0.4354865252971649, 'coordinates': [474.07220458984375, 265.149658203125, 839.9091186523438, 461.016845703125]}]\n",
      "Frame 530: [{'class': 'car', 'confidence': 0.7900768518447876, 'coordinates': [493.2330627441406, 251.70437622070312, 810.3614501953125, 455.0060119628906]}]\n",
      "Frame 540: [{'class': 'car', 'confidence': 0.8333926796913147, 'coordinates': [513.9080810546875, 313.13201904296875, 772.6756591796875, 451.70025634765625]}]\n",
      "Frame 550: [{'class': 'car', 'confidence': 0.8575486540794373, 'coordinates': [514.4515991210938, 305.1225891113281, 799.4039916992188, 453.3290100097656]}]\n",
      "Frame 560: [{'class': 'car', 'confidence': 0.6960704922676086, 'coordinates': [534.3719482421875, 312.1717529296875, 822.8165283203125, 475.1363525390625]}]\n",
      "Frame 570: [{'class': 'car', 'confidence': 0.6386656165122986, 'coordinates': [548.8944091796875, 306.76898193359375, 881.9190673828125, 501.93280029296875]}]\n",
      "Frame 580: []\n",
      "Frame 590: []\n",
      "Frame 600: [{'class': 'plane', 'confidence': 0.4338446259498596, 'coordinates': [280.4677734375, 111.82073974609375, 837.3538818359375, 371.9219970703125]}]\n",
      "Frame 610: [{'class': 'car', 'confidence': 0.5475784540176392, 'coordinates': [280.3677978515625, 128.1222381591797, 966.100341796875, 467.48175048828125]}]\n",
      "Frame 620: []\n",
      "Frame 630: []\n",
      "Frame 640: [{'class': 'plane', 'confidence': 0.3196292519569397, 'coordinates': [280.91748046875, 130.56185913085938, 658.386962890625, 285.8282775878906]}]\n",
      "Frame 650: [{'class': 'plane', 'confidence': 0.374470978975296, 'coordinates': [280.600830078125, 128.03744506835938, 798.1630859375, 411.1391906738281]}]\n",
      "Frame 660: [{'class': 'car', 'confidence': 0.5382717847824097, 'coordinates': [320.804443359375, 155.64910888671875, 731.2003173828125, 527.4979858398438]}]\n",
      "Frame 670: []\n",
      "Frame 680: []\n",
      "Frame 690: [{'class': 'car', 'confidence': 0.7487668991088867, 'coordinates': [411.8213195800781, 283.68865966796875, 869.6640625, 425.48626708984375]}]\n",
      "Frame 700: [{'class': 'car', 'confidence': 0.8050037622451782, 'coordinates': [416.6441955566406, 280.945068359375, 886.9508056640625, 445.283935546875]}]\n",
      "Frame 710: [{'class': 'car', 'confidence': 0.6264851093292236, 'coordinates': [412.68865966796875, 276.00616455078125, 887.3428344726562, 460.30560302734375]}]\n",
      "Frame 720: [{'class': 'car', 'confidence': 0.7168998122215271, 'coordinates': [425.14837646484375, 263.82000732421875, 893.8908081054688, 471.7047119140625]}, {'class': 'car', 'confidence': 0.44834914803504944, 'coordinates': [287.87530517578125, 255.5931396484375, 469.41265869140625, 335.4925537109375]}]\n",
      "Frame 730: [{'class': 'car', 'confidence': 0.7451916337013245, 'coordinates': [522.0250244140625, 248.1607666015625, 949.1002197265625, 489.483154296875]}, {'class': 'car', 'confidence': 0.45427900552749634, 'coordinates': [294.1739501953125, 235.60562133789062, 478.202392578125, 315.0360412597656]}]\n",
      "Frame 740: [{'class': 'car', 'confidence': 0.7929251194000244, 'coordinates': [586.26220703125, 230.537841796875, 967.320556640625, 518.4136352539062]}, {'class': 'car', 'confidence': 0.5590133666992188, 'coordinates': [394.8826904296875, 216.74761962890625, 571.0166015625, 296.3885498046875]}]\n",
      "Frame 750: [{'class': 'car', 'confidence': 0.7691430449485779, 'coordinates': [375.65118408203125, 214.7456512451172, 1000.2549438476562, 563.5879516601562]}]\n",
      "Frame 760: [{'class': 'car', 'confidence': 0.7847407460212708, 'coordinates': [280.7669677734375, 189.8812713623047, 999.9737548828125, 543.8751831054688]}]\n",
      "Frame 770: [{'class': 'car', 'confidence': 0.7934540510177612, 'coordinates': [284.21435546875, 173.55165100097656, 1000.2095947265625, 570.18212890625]}]\n",
      "Frame 780: [{'class': 'car', 'confidence': 0.8972432613372803, 'coordinates': [494.321044921875, 151.32437133789062, 985.5679931640625, 468.9884338378906]}]\n",
      "Frame 790: [{'class': 'car', 'confidence': 0.8470599055290222, 'coordinates': [280.375, 181.43722534179688, 801.5660400390625, 428.4340515136719]}]\n",
      "Frame 800: [{'class': 'car', 'confidence': 0.8843826055526733, 'coordinates': [280.42169189453125, 187.47653198242188, 759.2611694335938, 402.9105529785156]}]\n",
      "Frame 810: [{'class': 'car', 'confidence': 0.8324494361877441, 'coordinates': [280.718017578125, 190.478515625, 761.0538330078125, 393.6864013671875]}]\n",
      "Frame 820: [{'class': 'car', 'confidence': 0.8554538488388062, 'coordinates': [379.3464050292969, 203.2634735107422, 762.717041015625, 390.27008056640625]}]\n",
      "Frame 830: [{'class': 'car', 'confidence': 0.8496739268302917, 'coordinates': [463.9519958496094, 212.3001708984375, 713.5882568359375, 395.09576416015625]}]\n",
      "Frame 840: [{'class': 'car', 'confidence': 0.9010738134384155, 'coordinates': [414.3608093261719, 211.11293029785156, 735.555908203125, 396.219970703125]}]\n",
      "Frame 850: [{'class': 'car', 'confidence': 0.8453688621520996, 'coordinates': [354.97393798828125, 209.12899780273438, 830.6483764648438, 398.7780456542969]}]\n",
      "Frame 860: [{'class': 'car', 'confidence': 0.8261963129043579, 'coordinates': [296.30450439453125, 210.82586669921875, 901.5219116210938, 411.9222412109375]}]\n",
      "Frame 870: [{'class': 'car', 'confidence': 0.8902068734169006, 'coordinates': [280.6551818847656, 208.7717742919922, 927.4552001953125, 436.25775146484375]}]\n",
      "Frame 880: [{'class': 'car', 'confidence': 0.8984664082527161, 'coordinates': [279.21630859375, 196.45352172851562, 867.8367919921875, 451.1617736816406]}]\n",
      "Frame 890: [{'class': 'car', 'confidence': 0.9311546087265015, 'coordinates': [280.6731262207031, 174.4788360595703, 790.598876953125, 439.10772705078125]}]\n",
      "Frame 900: [{'class': 'car', 'confidence': 0.8919194936752319, 'coordinates': [280.42633056640625, 166.9235382080078, 743.4736938476562, 405.82586669921875]}]\n",
      "Frame 910: [{'class': 'car', 'confidence': 0.8476132750511169, 'coordinates': [278.91644287109375, 168.66452026367188, 762.3374633789062, 383.2751770019531]}]\n",
      "Frame 920: [{'class': 'car', 'confidence': 0.8217137455940247, 'coordinates': [281.7181396484375, 174.9993896484375, 789.695068359375, 354.6497802734375]}]\n",
      "Frame 930: [{'class': 'car', 'confidence': 0.7826336026191711, 'coordinates': [320.98223876953125, 175.57769775390625, 778.6994018554688, 330.6795654296875]}]\n",
      "Frame 940: []\n",
      "Frame 950: []\n",
      "Frame 960: [{'class': 'car', 'confidence': 0.8135976195335388, 'coordinates': [387.00164794921875, 274.8966979980469, 560.9149780273438, 412.1744689941406]}]\n",
      "Frame 970: [{'class': 'car', 'confidence': 0.8802464008331299, 'coordinates': [427.11773681640625, 265.8973388671875, 577.4302368164062, 382.32354736328125]}]\n",
      "Frame 980: []\n",
      "Frame 990: [{'class': 'car', 'confidence': 0.425167441368103, 'coordinates': [543.5379028320312, 210.34671020507812, 705.4055786132812, 271.7270812988281]}]\n",
      "Frame 1000: [{'class': 'car', 'confidence': 0.8171882033348083, 'coordinates': [543.0081787109375, 198.46157836914062, 705.541748046875, 252.10794067382812]}]\n",
      "Frame 1010: [{'class': 'car', 'confidence': 0.7277506589889526, 'coordinates': [582.2635498046875, 163.51419067382812, 743.3060302734375, 212.67181396484375]}]\n",
      "Frame 1020: [{'class': 'car', 'confidence': 0.7503815293312073, 'coordinates': [636.44140625, 129.458251953125, 804.57373046875, 181.03472900390625]}]\n",
      "Frame 1030: [{'class': 'car', 'confidence': 0.8413410186767578, 'coordinates': [638.1922607421875, 130.37640380859375, 815.8375244140625, 194.421142578125]}]\n",
      "Frame 1040: [{'class': 'car', 'confidence': 0.847557783126831, 'coordinates': [644.4283447265625, 135.48849487304688, 838.8973388671875, 226.25296020507812]}]\n",
      "Frame 1050: [{'class': 'car', 'confidence': 0.823660135269165, 'coordinates': [681.6661376953125, 133.695556640625, 876.0147705078125, 305.32373046875]}]\n",
      "Frame 1060: [{'class': 'car', 'confidence': 0.7830221056938171, 'coordinates': [517.404052734375, 196.8605194091797, 898.06103515625, 471.82818603515625]}]\n",
      "Frame 1070: [{'class': 'car', 'confidence': 0.37855154275894165, 'coordinates': [356.17919921875, 272.53753662109375, 914.5869140625, 561.557373046875]}]\n",
      "Frame 1080: [{'class': 'car', 'confidence': 0.7571203708648682, 'coordinates': [383.2060546875, 248.11248779296875, 706.84716796875, 461.4197998046875]}]\n",
      "Frame 1090: [{'class': 'car', 'confidence': 0.916694164276123, 'coordinates': [466.7032470703125, 271.58294677734375, 629.3157958984375, 409.10699462890625]}]\n",
      "Frame 1100: [{'class': 'car', 'confidence': 0.7575086355209351, 'coordinates': [502.1956481933594, 369.081787109375, 669.1192626953125, 462.879150390625]}]\n",
      "Frame 1110: [{'class': 'car', 'confidence': 0.6099494695663452, 'coordinates': [353.7884521484375, 106.17066955566406, 897.1171875, 359.8114013671875]}]\n",
      "Frame 1120: [{'class': 'car', 'confidence': 0.5677350759506226, 'coordinates': [444.6104736328125, 527.2800903320312, 603.1048583984375, 579.5597534179688]}, {'class': 'car', 'confidence': 0.44445762038230896, 'coordinates': [687.27099609375, 205.72625732421875, 923.05029296875, 441.88714599609375]}]\n",
      "Frame 1130: [{'class': 'car', 'confidence': 0.7212870121002197, 'coordinates': [421.47119140625, 576.0023193359375, 579.3504638671875, 633.1756591796875]}]\n",
      "Frame 1140: []\n",
      "Frame 1150: [{'class': 'car', 'confidence': 0.6580193042755127, 'coordinates': [353.5892333984375, 298.5335388183594, 713.254150390625, 420.0353698730469]}]\n",
      "Frame 1160: []\n",
      "Frame 1170: [{'class': 'car', 'confidence': 0.4512457549571991, 'coordinates': [393.73651123046875, 268.95318603515625, 661.2129516601562, 399.86700439453125]}]\n",
      "Frame 1180: [{'class': 'car', 'confidence': 0.5741240382194519, 'coordinates': [355.3320007324219, 270.8677978515625, 745.7900390625, 405.9930419921875]}]\n",
      "Frame 1190: [{'class': 'car', 'confidence': 0.6994200944900513, 'coordinates': [354.22076416015625, 277.642822265625, 818.4362182617188, 418.438720703125]}]\n",
      "Frame 1200: [{'class': 'car', 'confidence': 0.5131402611732483, 'coordinates': [487.1148681640625, 283.9678039550781, 860.4769287109375, 447.7013244628906]}]\n",
      "Frame 1210: []\n",
      "Frame 1220: []\n",
      "Frame 1230: []\n",
      "Frame 1240: []\n",
      "Frame 1250: []\n",
      "Frame 1260: []\n",
      "Frame 1270: []\n",
      "Frame 1280: [{'class': 'car', 'confidence': 0.5700387358665466, 'coordinates': [451.2142028808594, 120.49761962890625, 751.3648681640625, 345.480712890625]}, {'class': 'car', 'confidence': 0.41589051485061646, 'coordinates': [792.4437255859375, 102.08245849609375, 850.7857666015625, 148.33438110351562]}]\n",
      "Frame 1290: [{'class': 'car', 'confidence': 0.5075372457504272, 'coordinates': [478.4649658203125, 99.4726791381836, 824.7021484375, 353.1372985839844]}, {'class': 'car', 'confidence': 0.4503242075443268, 'coordinates': [796.133544921875, 79.82351684570312, 855.275390625, 126.08432006835938]}]\n",
      "Frame 1300: [{'class': 'car', 'confidence': 0.7077862620353699, 'coordinates': [472.5997314453125, 90.34239196777344, 884.46435546875, 381.8272705078125]}, {'class': 'car', 'confidence': 0.4163571894168854, 'coordinates': [763.3617553710938, 69.2117919921875, 822.3705444335938, 114.08624267578125]}]\n",
      "Frame 1310: [{'class': 'car', 'confidence': 0.7362250685691833, 'coordinates': [447.41339111328125, 88.40478515625, 946.0317993164062, 433.23492431640625]}]\n",
      "Frame 1320: [{'class': 'car', 'confidence': 0.6426530480384827, 'coordinates': [473.8682861328125, 91.35353088378906, 1000.33251953125, 511.320068359375]}]\n",
      "Frame 1330: [{'class': 'car', 'confidence': 0.7496992349624634, 'coordinates': [542.5465698242188, 107.4969482421875, 1000.8401489257812, 654.9217529296875]}]\n",
      "Frame 1340: [{'class': 'car', 'confidence': 0.8056384325027466, 'coordinates': [658.0283813476562, 127.541259765625, 999.9656372070312, 720.0]}, {'class': 'car', 'confidence': 0.3033997118473053, 'coordinates': [723.96435546875, 87.11769104003906, 781.50439453125, 132.6403045654297]}, {'class': 'car', 'confidence': 0.2514650821685791, 'coordinates': [378.919921875, 105.9232177734375, 630.351806640625, 286.7264709472656]}]\n",
      "Frame 1350: [{'class': 'car', 'confidence': 0.8467276692390442, 'coordinates': [807.013916015625, 178.915283203125, 1000.0799560546875, 720.0]}, {'class': 'car', 'confidence': 0.43284496665000916, 'coordinates': [410.8607482910156, 110.05703735351562, 692.0955810546875, 310.8216857910156]}, {'class': 'car', 'confidence': 0.30541807413101196, 'coordinates': [741.1653442382812, 90.3504638671875, 799.5305786132812, 134.86825561523438]}]\n",
      "Frame 1360: [{'class': 'car', 'confidence': 0.5424455404281616, 'coordinates': [434.47113037109375, 110.3577880859375, 751.2717895507812, 334.89422607421875]}, {'class': 'car', 'confidence': 0.4482635259628296, 'coordinates': [747.7454833984375, 89.93142700195312, 804.8955078125, 133.82098388671875]}]\n",
      "Frame 1370: [{'class': 'car', 'confidence': 0.5142295360565186, 'coordinates': [454.6000671386719, 110.833984375, 826.385986328125, 364.33929443359375]}, {'class': 'car', 'confidence': 0.46647652983665466, 'coordinates': [747.689453125, 85.76956176757812, 806.2958984375, 131.5928955078125]}]\n",
      "Frame 1380: [{'class': 'car', 'confidence': 0.673484742641449, 'coordinates': [481.8237609863281, 110.1212158203125, 919.38427734375, 404.84228515625]}]\n",
      "Frame 1390: [{'class': 'car', 'confidence': 0.5743856430053711, 'coordinates': [510.019775390625, 109.72065734863281, 1001.1397705078125, 462.10723876953125]}, {'class': 'car', 'confidence': 0.2532976269721985, 'coordinates': [738.0999755859375, 75.73051452636719, 799.0933837890625, 116.72840881347656]}]\n",
      "Frame 1400: [{'class': 'car', 'confidence': 0.7414369583129883, 'coordinates': [550.1885375976562, 113.3211669921875, 1000.6992797851562, 552.5108642578125]}]\n",
      "Frame 1410: [{'class': 'car', 'confidence': 0.716902494430542, 'coordinates': [610.7518310546875, 122.133544921875, 1000.368896484375, 720.0]}, {'class': 'car', 'confidence': 0.34969645738601685, 'coordinates': [717.6537475585938, 68.89169311523438, 777.6439819335938, 114.78521728515625]}]\n",
      "Frame 1420: [{'class': 'car', 'confidence': 0.7563416957855225, 'coordinates': [706.081298828125, 139.23919677734375, 1000.1201171875, 714.5521240234375]}, {'class': 'car', 'confidence': 0.41201600432395935, 'coordinates': [399.1225280761719, 98.11126708984375, 681.22021484375, 296.20904541015625]}, {'class': 'car', 'confidence': 0.2857753038406372, 'coordinates': [712.1549072265625, 66.23776245117188, 771.7515869140625, 111.49615478515625]}]\n",
      "Frame 1430: [{'class': 'car', 'confidence': 0.7204224467277527, 'coordinates': [866.5272216796875, 283.2315673828125, 1000.1253662109375, 719.7445068359375]}, {'class': 'car', 'confidence': 0.5172908902168274, 'coordinates': [418.045654296875, 100.07270050048828, 740.7474365234375, 323.62677001953125]}]\n",
      "Frame 1440: [{'class': 'car', 'confidence': 0.5972762107849121, 'coordinates': [447.33831787109375, 99.9134521484375, 825.1199340820312, 362.29498291015625]}]\n",
      "Frame 1450: [{'class': 'car', 'confidence': 0.683695912361145, 'coordinates': [488.27166748046875, 109.78358459472656, 963.2885131835938, 424.952880859375]}]\n",
      "Frame 1460: [{'class': 'car', 'confidence': 0.6576327085494995, 'coordinates': [536.7435302734375, 114.45674133300781, 999.9964599609375, 500.45220947265625]}, {'class': 'car', 'confidence': 0.34765496850013733, 'coordinates': [714.5305786132812, 58.6292724609375, 772.8311157226562, 102.74359130859375]}]\n",
      "Frame 1470: [{'class': 'car', 'confidence': 0.7205987572669983, 'coordinates': [604.6025390625, 119.31744384765625, 999.9296875, 627.80712890625]}, {'class': 'car', 'confidence': 0.34698155522346497, 'coordinates': [712.1312866210938, 52.15794372558594, 772.2630004882812, 96.17050170898438]}]\n",
      "Frame 1480: [{'class': 'car', 'confidence': 0.7154735326766968, 'coordinates': [698.97119140625, 136.01123046875, 1000.01123046875, 716.6657104492188]}, {'class': 'car', 'confidence': 0.2569989562034607, 'coordinates': [405.6748962402344, 39.924842834472656, 662.9505615234375, 255.75717163085938]}]\n",
      "Frame 1490: [{'class': 'car', 'confidence': 0.7541188597679138, 'coordinates': [853.4852294921875, 251.526123046875, 999.9110107421875, 718.8175048828125]}, {'class': 'car', 'confidence': 0.29788944125175476, 'coordinates': [280.5015869140625, 42.10125732421875, 325.44921875, 64.03776550292969]}, {'class': 'car', 'confidence': 0.2799309194087982, 'coordinates': [419.47772216796875, 38.1170654296875, 706.7979125976562, 270.89898681640625]}, {'class': 'car', 'confidence': 0.2548770010471344, 'coordinates': [707.9932861328125, 42.311676025390625, 768.2293701171875, 88.91331481933594]}]\n",
      "Frame 1500: [{'class': 'car', 'confidence': 0.379115492105484, 'coordinates': [438.5703125, 36.512664794921875, 761.6226806640625, 289.1597900390625]}, {'class': 'car', 'confidence': 0.2518516182899475, 'coordinates': [293.0099792480469, 38.72235107421875, 342.2417907714844, 60.845611572265625]}]\n",
      "Frame 1510: [{'class': 'car', 'confidence': 0.40209195017814636, 'coordinates': [459.6936950683594, 29.06243896484375, 833.0867919921875, 319.25506591796875]}]\n",
      "Frame 1520: [{'class': 'car', 'confidence': 0.5908282995223999, 'coordinates': [484.372314453125, 28.0914306640625, 912.0438232421875, 353.54034423828125]}]\n",
      "Frame 1530: [{'class': 'car', 'confidence': 0.5189573168754578, 'coordinates': [515.8719482421875, 26.91351318359375, 1000.1697998046875, 402.35333251953125]}]\n",
      "Frame 1540: [{'class': 'car', 'confidence': 0.6011061072349548, 'coordinates': [542.7890625, 25.078643798828125, 1000.7830810546875, 472.9482727050781]}]\n",
      "Frame 1550: [{'class': 'car', 'confidence': 0.6653963327407837, 'coordinates': [605.2216186523438, 31.606201171875, 999.8967895507812, 576.4063720703125]}]\n",
      "Frame 1560: [{'class': 'car', 'confidence': 0.6690278649330139, 'coordinates': [684.0119018554688, 31.51898193359375, 1000.2133178710938, 716.6719970703125]}, {'class': 'car', 'confidence': 0.3252471387386322, 'coordinates': [688.112060546875, 57.577850341796875, 745.408447265625, 101.6029052734375]}, {'class': 'car', 'confidence': 0.3103691339492798, 'coordinates': [379.8662109375, 49.82806396484375, 653.194580078125, 279.123046875]}]\n",
      "Frame 1570: [{'class': 'car', 'confidence': 0.46164435148239136, 'coordinates': [802.5714111328125, 33.75177001953125, 999.951904296875, 641.32421875]}, {'class': 'car', 'confidence': 0.2612922787666321, 'coordinates': [393.2622375488281, 55.439910888671875, 700.193115234375, 302.9785461425781]}]\n",
      "Frame 1580: [{'class': 'car', 'confidence': 0.5219475626945496, 'coordinates': [409.5213928222656, 54.31732177734375, 760.6959228515625, 331.361083984375]}]\n",
      "Frame 1590: [{'class': 'car', 'confidence': 0.6247550845146179, 'coordinates': [434.84185791015625, 52.425567626953125, 837.8656616210938, 365.6283264160156]}, {'class': 'car', 'confidence': 0.2770361304283142, 'coordinates': [324.368408203125, 55.40782165527344, 483.7647705078125, 226.3607940673828]}]\n",
      "Frame 1600: [{'class': 'car', 'confidence': 0.6738185286521912, 'coordinates': [462.1841125488281, 45.36834716796875, 943.0556640625, 406.68023681640625]}]\n",
      "Frame 1610: [{'class': 'car', 'confidence': 0.344315767288208, 'coordinates': [504.1523132324219, 36.71971130371094, 1000.334716796875, 460.0771484375]}]\n",
      "Frame 1620: [{'class': 'car', 'confidence': 0.5132936835289001, 'coordinates': [557.011474609375, 27.44775390625, 1000.7305908203125, 542.03857421875]}]\n",
      "Frame 1630: [{'class': 'car', 'confidence': 0.6696901917457581, 'coordinates': [629.64697265625, 16.43157958984375, 999.77685546875, 668.1608276367188]}]\n",
      "Frame 1640: [{'class': 'car', 'confidence': 0.5963817238807678, 'coordinates': [722.949951171875, 9.8446044921875, 1000.5654296875, 628.5758056640625]}]\n",
      "Frame 1650: [{'class': 'car', 'confidence': 0.6195697784423828, 'coordinates': [873.090087890625, 58.0699462890625, 1000.0147705078125, 719.7958984375]}]\n",
      "Frame 1660: [{'class': 'car', 'confidence': 0.3549250662326813, 'coordinates': [448.0619812011719, 9.04638671875, 877.13623046875, 378.42779541015625]}]\n",
      "Frame 1670: [{'class': 'car', 'confidence': 0.35765165090560913, 'coordinates': [485.3759765625, 4.092437744140625, 999.5694580078125, 433.9534606933594]}]\n",
      "Frame 1680: [{'class': 'car', 'confidence': 0.4348571300506592, 'coordinates': [543.3406982421875, 0.544189453125, 1000.6458740234375, 525.4154052734375]}]\n",
      "Frame 1690: [{'class': 'car', 'confidence': 0.6063434481620789, 'coordinates': [605.2091064453125, 0.0, 1000.0762939453125, 643.798095703125]}]\n",
      "Frame 1700: []\n",
      "Frame 1710: []\n",
      "Frame 1720: [{'class': 'car', 'confidence': 0.8226495981216431, 'coordinates': [331.7886962890625, 172.5006103515625, 1072.5911865234375, 480.2474365234375]}, {'class': 'car', 'confidence': 0.28253477811813354, 'coordinates': [0.0, 0.393829345703125, 525.2178344726562, 304.9725341796875]}]\n",
      "Frame 1730: [{'class': 'car', 'confidence': 0.7583638429641724, 'coordinates': [344.167724609375, 199.49237060546875, 1029.0125732421875, 483.62548828125]}, {'class': 'car', 'confidence': 0.27101930975914, 'coordinates': [825.709228515625, 90.15219116210938, 1009.50439453125, 269.9244384765625]}]\n",
      "Frame 1740: [{'class': 'car', 'confidence': 0.7553901672363281, 'coordinates': [343.14617919921875, 175.78355407714844, 960.0259399414062, 429.851318359375]}]\n",
      "Frame 1750: [{'class': 'car', 'confidence': 0.6933778524398804, 'coordinates': [318.8711242675781, 197.7496795654297, 864.292724609375, 400.80560302734375]}]\n",
      "Frame 1760: [{'class': 'car', 'confidence': 0.8021193146705627, 'coordinates': [287.2693786621094, 218.46951293945312, 751.7105712890625, 392.0218200683594]}]\n",
      "Frame 1770: [{'class': 'car', 'confidence': 0.8795143961906433, 'coordinates': [332.20892333984375, 231.5219268798828, 702.9579467773438, 367.27691650390625]}, {'class': 'car', 'confidence': 0.38680458068847656, 'coordinates': [874.5253295898438, 0.0, 1280.0, 327.6478271484375]}]\n",
      "Frame 1780: [{'class': 'car', 'confidence': 0.9116755127906799, 'coordinates': [395.11541748046875, 249.05319213867188, 676.9644165039062, 355.2499694824219]}]\n",
      "Frame 1790: [{'class': 'car', 'confidence': 0.8830593228340149, 'coordinates': [414.1136474609375, 259.8526306152344, 627.9947509765625, 347.6696472167969]}]\n",
      "Frame 1800: [{'class': 'car', 'confidence': 0.8307907581329346, 'coordinates': [471.0322265625, 273.0590515136719, 631.9639892578125, 343.9170837402344]}]\n",
      "Frame 1810: [{'class': 'car', 'confidence': 0.6775873303413391, 'coordinates': [545.2777099609375, 286.98358154296875, 671.3177490234375, 343.66741943359375]}]\n",
      "Frame 1820: [{'class': 'car', 'confidence': 0.7637538313865662, 'coordinates': [0.0, 352.6587829589844, 135.41319274902344, 625.4595947265625]}, {'class': 'car', 'confidence': 0.25114893913269043, 'coordinates': [354.6387939453125, 315.1640930175781, 405.0633544921875, 340.3159484863281]}]\n",
      "Frame 1830: [{'class': 'car', 'confidence': 0.6828269958496094, 'coordinates': [0.0, 355.65447998046875, 248.27847290039062, 631.9168090820312]}, {'class': 'car', 'confidence': 0.2938241958618164, 'coordinates': [627.7410278320312, 308.0609436035156, 698.7935180664062, 337.9859313964844]}]\n",
      "Frame 1840: [{'class': 'car', 'confidence': 0.7303738594055176, 'coordinates': [0.0, 364.25927734375, 299.7589111328125, 653.7281494140625]}, {'class': 'car', 'confidence': 0.2700669765472412, 'coordinates': [622.9730224609375, 321.2547607421875, 673.23388671875, 344.046630859375]}]\n",
      "Frame 1850: [{'class': 'car', 'confidence': 0.7249047160148621, 'coordinates': [0.47650146484375, 349.5747375488281, 332.8297119140625, 633.181884765625]}]\n",
      "Frame 1860: []\n",
      "Frame 1870: []\n",
      "Frame 1880: [{'class': 'car', 'confidence': 0.8805371522903442, 'coordinates': [279.5593566894531, 341.04052734375, 967.783447265625, 582.0859985351562]}]\n",
      "Frame 1890: [{'class': 'car', 'confidence': 0.9111219644546509, 'coordinates': [279.5647277832031, 325.4720458984375, 882.5009765625, 574.3836059570312]}]\n",
      "Frame 1900: [{'class': 'car', 'confidence': 0.9423542022705078, 'coordinates': [305.3896179199219, 313.72320556640625, 742.685302734375, 548.63232421875]}]\n",
      "Frame 1910: [{'class': 'car', 'confidence': 0.8103843927383423, 'coordinates': [522.0611572265625, 302.75927734375, 865.6082763671875, 527.74658203125]}]\n",
      "Frame 1920: [{'class': 'car', 'confidence': 0.7289168238639832, 'coordinates': [505.21990966796875, 293.401123046875, 997.6022338867188, 489.0567626953125]}]\n",
      "Frame 1930: [{'class': 'car', 'confidence': 0.8503395318984985, 'coordinates': [453.32080078125, 295.2506103515625, 1000.6669921875, 467.627685546875]}]\n",
      "Frame 1940: [{'class': 'car', 'confidence': 0.8332447409629822, 'coordinates': [419.2882080078125, 304.062255859375, 951.9749755859375, 461.715576171875]}]\n",
      "Frame 1950: [{'class': 'car', 'confidence': 0.8873818516731262, 'coordinates': [423.7425231933594, 310.5771484375, 930.2662353515625, 461.3453369140625]}]\n",
      "Frame 1960: [{'class': 'car', 'confidence': 0.8003689646720886, 'coordinates': [433.475830078125, 315.05816650390625, 883.58251953125, 463.0406494140625]}]\n",
      "Frame 1970: [{'class': 'car', 'confidence': 0.8820520639419556, 'coordinates': [405.33331298828125, 329.0743103027344, 750.8490600585938, 472.6173400878906]}]\n",
      "Frame 1980: [{'class': 'car', 'confidence': 0.9069910645484924, 'coordinates': [364.1138916015625, 318.94049072265625, 597.0896606445312, 468.51605224609375]}]\n",
      "Frame 1990: [{'class': 'car', 'confidence': 0.8918326497077942, 'coordinates': [300.29852294921875, 328.7799987792969, 556.3364868164062, 483.5773010253906]}]\n",
      "Frame 2000: [{'class': 'car', 'confidence': 0.8307605385780334, 'coordinates': [280.638916015625, 337.98504638671875, 566.30859375, 505.5499267578125]}]\n",
      "Frame 2010: [{'class': 'car', 'confidence': 0.5847702622413635, 'coordinates': [280.8177490234375, 352.77239990234375, 619.4022216796875, 528.2471313476562]}]\n",
      "Frame 2020: [{'class': 'car', 'confidence': 0.9110829830169678, 'coordinates': [280.35406494140625, 351.35791015625, 737.3363647460938, 554.5883178710938]}]\n",
      "Frame 2030: [{'class': 'car', 'confidence': 0.883368968963623, 'coordinates': [305.4276123046875, 350.72314453125, 999.4969482421875, 575.7635498046875]}]\n",
      "Frame 2040: [{'class': 'car', 'confidence': 0.8935149908065796, 'coordinates': [318.545654296875, 357.53277587890625, 1001.120849609375, 595.1746215820312]}]\n",
      "Frame 2050: [{'class': 'car', 'confidence': 0.9169986248016357, 'coordinates': [376.5078430175781, 367.74072265625, 1000.40087890625, 623.3333740234375]}]\n",
      "Frame 2060: [{'class': 'car', 'confidence': 0.8221047520637512, 'coordinates': [575.8125, 361.644287109375, 930.745361328125, 619.3720703125]}]\n",
      "Frame 2070: [{'class': 'car', 'confidence': 0.47250473499298096, 'coordinates': [644.7902221679688, 356.06817626953125, 1000.3164672851562, 611.9862670898438]}]\n",
      "Frame 2080: [{'class': 'car', 'confidence': 0.6849882006645203, 'coordinates': [624.1356201171875, 350.5770263671875, 999.7659912109375, 542.5790405273438]}]\n",
      "Frame 2090: [{'class': 'car', 'confidence': 0.4443598687648773, 'coordinates': [575.353515625, 347.44720458984375, 1000.5537109375, 527.3182983398438]}]\n",
      "Frame 2100: [{'class': 'car', 'confidence': 0.7953811883926392, 'coordinates': [452.5418701171875, 338.99072265625, 1000.1334228515625, 518.3857421875]}, {'class': 'plane', 'confidence': 0.42842257022857666, 'coordinates': [451.2529296875, 339.77154541015625, 1000.694091796875, 517.0736083984375]}]\n",
      "Frame 2110: [{'class': 'car', 'confidence': 0.8096190094947815, 'coordinates': [363.6426086425781, 335.0594482421875, 920.203857421875, 497.44659423828125]}]\n",
      "Frame 2120: [{'class': 'car', 'confidence': 0.7672735452651978, 'coordinates': [284.3973388671875, 341.42315673828125, 824.20654296875, 500.49163818359375]}]\n",
      "Frame 2130: [{'class': 'car', 'confidence': 0.7559300661087036, 'coordinates': [279.6399841308594, 331.11932373046875, 781.7281494140625, 488.5283203125]}]\n",
      "Frame 2140: [{'class': 'car', 'confidence': 0.5791998505592346, 'coordinates': [284.0714111328125, 325.91375732421875, 724.2003173828125, 472.16693115234375]}]\n",
      "Frame 2150: [{'class': 'car', 'confidence': 0.5719648599624634, 'coordinates': [281.548828125, 330.1435241699219, 702.8980712890625, 467.5346374511719]}]\n",
      "Frame 2160: [{'class': 'plane', 'confidence': 0.2720228433609009, 'coordinates': [286.590087890625, 331.60675048828125, 789.663330078125, 502.03680419921875]}]\n",
      "Frame 2170: [{'class': 'car', 'confidence': 0.7867367267608643, 'coordinates': [281.5985107421875, 345.09478759765625, 575.543701171875, 455.19134521484375]}]\n",
      "Frame 2180: []\n",
      "Frame 2190: []\n",
      "Frame 2200: [{'class': 'car', 'confidence': 0.6073350310325623, 'coordinates': [599.4322509765625, 19.501937866210938, 999.7818603515625, 453.9730224609375]}, {'class': 'car', 'confidence': 0.50413978099823, 'coordinates': [281.3365478515625, 2.05328369140625, 589.860595703125, 669.23828125]}]\n",
      "Frame 2210: [{'class': 'car', 'confidence': 0.6951655149459839, 'coordinates': [602.84375, 32.241241455078125, 999.602783203125, 455.7333068847656]}, {'class': 'car', 'confidence': 0.5547086596488953, 'coordinates': [281.310791015625, 3.9801025390625, 621.3868408203125, 667.0155029296875]}]\n",
      "Frame 2220: [{'class': 'car', 'confidence': 0.6673543453216553, 'coordinates': [281.072021484375, 1.748779296875, 620.81884765625, 670.37060546875]}, {'class': 'car', 'confidence': 0.39785459637641907, 'coordinates': [602.5687255859375, 35.16062927246094, 1000.2542724609375, 454.9971923828125]}]\n",
      "Frame 2230: [{'class': 'car', 'confidence': 0.779841959476471, 'coordinates': [594.9730224609375, 28.4171142578125, 999.3834228515625, 443.6300048828125]}, {'class': 'car', 'confidence': 0.5222521424293518, 'coordinates': [280.880615234375, 36.85540771484375, 625.537841796875, 674.218505859375]}]\n",
      "Frame 2240: [{'class': 'car', 'confidence': 0.7220262289047241, 'coordinates': [280.64862060546875, 77.99017333984375, 593.373291015625, 658.7013549804688]}, {'class': 'car', 'confidence': 0.7081008553504944, 'coordinates': [563.1015625, 23.992324829101562, 999.6793212890625, 457.640625]}]\n",
      "Frame 2250: [{'class': 'car', 'confidence': 0.7436602711677551, 'coordinates': [510.6429443359375, 24.5489501953125, 1000.0780029296875, 511.0401611328125]}]\n",
      "Frame 2260: [{'class': 'car', 'confidence': 0.8378065228462219, 'coordinates': [468.97686767578125, 9.363967895507812, 1000.2958374023438, 503.77960205078125]}, {'class': 'car', 'confidence': 0.5266578197479248, 'coordinates': [281.040283203125, 113.246826171875, 464.90496826171875, 549.03515625]}]\n",
      "Frame 2270: [{'class': 'car', 'confidence': 0.8405591249465942, 'coordinates': [450.5324401855469, 20.594970703125, 1000.125244140625, 556.6732177734375]}, {'class': 'car', 'confidence': 0.5759690999984741, 'coordinates': [281.3802490234375, 138.329833984375, 451.075439453125, 561.0556640625]}]\n",
      "Frame 2280: [{'class': 'car', 'confidence': 0.8465862274169922, 'coordinates': [410.3147277832031, 22.033203125, 1001.019775390625, 591.4075317382812]}, {'class': 'car', 'confidence': 0.6835322976112366, 'coordinates': [280.48773193359375, 178.18084716796875, 395.61065673828125, 503.6873779296875]}]\n",
      "Frame 2290: [{'class': 'car', 'confidence': 0.863423764705658, 'coordinates': [389.4468994140625, 9.5814208984375, 999.9110107421875, 605.64501953125]}, {'class': 'car', 'confidence': 0.6292205452919006, 'coordinates': [280.65673828125, 211.16363525390625, 351.7156982421875, 488.2864990234375]}]\n",
      "Frame 2300: [{'class': 'car', 'confidence': 0.8535571694374084, 'coordinates': [398.5814208984375, 28.92816162109375, 999.999755859375, 612.7496337890625]}, {'class': 'car', 'confidence': 0.6395936012268066, 'coordinates': [280.5972900390625, 204.15049743652344, 369.52490234375, 496.2550048828125]}]\n",
      "Frame 2310: [{'class': 'car', 'confidence': 0.7180554270744324, 'coordinates': [281.1473388671875, 162.91259765625, 431.7822265625, 548.6484375]}, {'class': 'car', 'confidence': 0.6484513878822327, 'coordinates': [437.37799072265625, 22.2427978515625, 1000.9019165039062, 571.9129638671875]}]\n",
      "Frame 2320: [{'class': 'car', 'confidence': 0.8136456608772278, 'coordinates': [480.4700927734375, 24.45196533203125, 999.6973876953125, 577.1110229492188]}, {'class': 'car', 'confidence': 0.4121795892715454, 'coordinates': [281.366455078125, 136.31243896484375, 484.4952392578125, 614.38232421875]}]\n",
      "Frame 2330: [{'class': 'car', 'confidence': 0.7512269020080566, 'coordinates': [509.8863525390625, 2.8287353515625, 999.95068359375, 556.90625]}, {'class': 'car', 'confidence': 0.5667464733123779, 'coordinates': [280.9140625, 142.79974365234375, 509.422607421875, 643.85009765625]}]\n",
      "Frame 2340: [{'class': 'car', 'confidence': 0.7436275482177734, 'coordinates': [520.44091796875, 59.045166015625, 1001.1202392578125, 563.0699462890625]}, {'class': 'car', 'confidence': 0.6917345523834229, 'coordinates': [280.9344177246094, 142.67547607421875, 495.8698425292969, 686.1870727539062]}]\n",
      "Frame 2350: [{'class': 'car', 'confidence': 0.8502748012542725, 'coordinates': [499.7467346191406, 63.33416748046875, 999.7396240234375, 561.2180786132812]}, {'class': 'car', 'confidence': 0.6601674556732178, 'coordinates': [281.01141357421875, 167.69354248046875, 444.34710693359375, 557.778076171875]}]\n",
      "Frame 2360: [{'class': 'car', 'confidence': 0.8900810480117798, 'coordinates': [462.4079284667969, 46.65582275390625, 1000.43115234375, 552.3909912109375]}, {'class': 'car', 'confidence': 0.723147988319397, 'coordinates': [280.7999267578125, 212.8743896484375, 364.4896240234375, 510.61962890625]}]\n",
      "Frame 2370: []\n",
      "Frame 2380: []\n",
      "Frame 2390: []\n",
      "Frame 2400: []\n",
      "Frame 2410: [{'class': 'car', 'confidence': 0.3818518817424774, 'coordinates': [279.52923583984375, 55.86395263671875, 902.7077026367188, 718.8388061523438]}]\n",
      "Frame 2420: [{'class': 'car', 'confidence': 0.7114046812057495, 'coordinates': [285.2877197265625, 57.3216552734375, 1000.718994140625, 654.818359375]}, {'class': 'car', 'confidence': 0.2931380271911621, 'coordinates': [280.677734375, 210.67103576660156, 339.911865234375, 432.9105224609375]}]\n",
      "Frame 2430: [{'class': 'car', 'confidence': 0.38263648748397827, 'coordinates': [436.337158203125, 65.1177978515625, 999.21337890625, 653.135498046875]}, {'class': 'car', 'confidence': 0.3243141770362854, 'coordinates': [441.6790466308594, 71.512451171875, 999.4840087890625, 382.39263916015625]}]\n",
      "Frame 2440: [{'class': 'car', 'confidence': 0.45144858956336975, 'coordinates': [529.9591064453125, 92.00320434570312, 998.3306884765625, 363.2143859863281]}, {'class': 'car', 'confidence': 0.3759230375289917, 'coordinates': [281.67864990234375, 121.30809020996094, 564.6315307617188, 625.4486083984375]}]\n",
      "Frame 2450: []\n",
      "Frame 2460: []\n",
      "Frame 2470: []\n",
      "Frame 2480: []\n",
      "Frame 2490: []\n",
      "Frame 2500: []\n",
      "Frame 2510: [{'class': 'car', 'confidence': 0.8932099342346191, 'coordinates': [282.7360534667969, 0.0, 1000.138671875, 598.9393920898438]}]\n",
      "Frame 2520: [{'class': 'car', 'confidence': 0.9004091620445251, 'coordinates': [280.274658203125, 0.0, 998.85107421875, 593.626953125]}]\n",
      "Frame 2530: [{'class': 'car', 'confidence': 0.8957626819610596, 'coordinates': [280.1784973144531, 0.0, 998.989013671875, 601.0363159179688]}]\n",
      "Frame 2540: [{'class': 'car', 'confidence': 0.8991594314575195, 'coordinates': [280.6580810546875, 0.0, 999.2618408203125, 608.2206420898438]}]\n",
      "Frame 2550: [{'class': 'car', 'confidence': 0.8909989595413208, 'coordinates': [280.6320495605469, 0.1690673828125, 1000.063720703125, 617.5982666015625]}]\n",
      "Frame 2560: [{'class': 'car', 'confidence': 0.8835667371749878, 'coordinates': [280.5101013183594, 0.0, 1000.0093994140625, 616.632568359375]}]\n",
      "Frame 2570: [{'class': 'car', 'confidence': 0.892866849899292, 'coordinates': [280.50421142578125, 0.0, 1000.2677612304688, 616.77197265625]}]\n",
      "Frame 2580: [{'class': 'car', 'confidence': 0.8917421698570251, 'coordinates': [285.906982421875, 0.0, 1000.029296875, 604.134765625]}]\n",
      "Frame 2590: [{'class': 'car', 'confidence': 0.9112570881843567, 'coordinates': [283.9766845703125, 0.0, 1001.1138916015625, 591.679931640625]}]\n",
      "Frame 2600: [{'class': 'car', 'confidence': 0.8928263783454895, 'coordinates': [280.314453125, 0.0, 999.0369873046875, 602.8500366210938]}]\n",
      "Frame 2610: [{'class': 'car', 'confidence': 0.8811988830566406, 'coordinates': [279.937744140625, 0.5997314453125, 1000.5887451171875, 628.0860595703125]}]\n",
      "Frame 2620: [{'class': 'car', 'confidence': 0.8409345149993896, 'coordinates': [280.211181640625, 2.6474609375, 975.452880859375, 651.685546875]}]\n",
      "Frame 2630: [{'class': 'car', 'confidence': 0.8441486954689026, 'coordinates': [280.702392578125, 18.62017822265625, 934.53662109375, 698.1776123046875]}]\n",
      "Frame 2640: [{'class': 'car', 'confidence': 0.8988516926765442, 'coordinates': [281.2868957519531, 28.1212158203125, 897.355712890625, 720.0]}]\n",
      "Frame 2650: [{'class': 'car', 'confidence': 0.9047380089759827, 'coordinates': [280.8136901855469, 2.496826171875, 892.104248046875, 720.0]}]\n",
      "Frame 2660: [{'class': 'car', 'confidence': 0.9049673080444336, 'coordinates': [281.5113525390625, 0.0, 934.5933837890625, 720.0]}]\n",
      "Frame 2670: [{'class': 'car', 'confidence': 0.9296704530715942, 'coordinates': [281.45391845703125, 0.0, 935.9514770507812, 719.76806640625]}]\n",
      "Frame 2680: [{'class': 'car', 'confidence': 0.9048184156417847, 'coordinates': [280.15106201171875, 0.0, 925.6489868164062, 720.0]}]\n",
      "Frame 2690: [{'class': 'car', 'confidence': 0.8959171772003174, 'coordinates': [281.3984375, 0.0, 908.1492919921875, 720.0]}]\n",
      "Frame 2700: [{'class': 'car', 'confidence': 0.9057562351226807, 'coordinates': [280.5025634765625, 0.0, 882.7086181640625, 720.0]}]\n",
      "Frame 2710: [{'class': 'car', 'confidence': 0.9159780144691467, 'coordinates': [281.0550231933594, 0.0, 867.2757568359375, 720.0]}]\n",
      "Frame 2720: [{'class': 'car', 'confidence': 0.9007257223129272, 'coordinates': [281.0465087890625, 0.0, 872.0360107421875, 720.0]}]\n",
      "Frame 2730: [{'class': 'car', 'confidence': 0.8916215896606445, 'coordinates': [280.5855712890625, 0.0, 809.91259765625, 712.8799438476562]}]\n",
      "Frame 2740: [{'class': 'car', 'confidence': 0.9163733124732971, 'coordinates': [280.2778625488281, 0.0, 786.444091796875, 717.3983764648438]}]\n",
      "Frame 2750: [{'class': 'car', 'confidence': 0.9098187685012817, 'coordinates': [281.2591552734375, 0.0, 776.7099609375, 719.983642578125]}]\n",
      "Frame 2760: [{'class': 'car', 'confidence': 0.9170002341270447, 'coordinates': [281.0877380371094, 0.0, 763.3841552734375, 720.0]}]\n",
      "Frame 2770: [{'class': 'car', 'confidence': 0.8581640720367432, 'coordinates': [280.906005859375, 25.48809814453125, 721.1942138671875, 720.0]}]\n",
      "Frame 2780: [{'class': 'car', 'confidence': 0.8743685483932495, 'coordinates': [281.17510986328125, 23.9085693359375, 772.4749145507812, 720.0]}]\n",
      "Frame 2790: [{'class': 'car', 'confidence': 0.843882143497467, 'coordinates': [280.813232421875, 3.1641845703125, 776.675537109375, 720.0]}]\n",
      "Frame 2800: [{'class': 'car', 'confidence': 0.8977455496788025, 'coordinates': [280.86956787109375, 34.24273681640625, 674.6437377929688, 720.0]}]\n",
      "Frame 2810: [{'class': 'car', 'confidence': 0.8824861645698547, 'coordinates': [280.48779296875, 27.908447265625, 679.4742431640625, 720.0]}]\n",
      "Frame 2820: [{'class': 'car', 'confidence': 0.8447943925857544, 'coordinates': [281.029296875, 0.31103515625, 625.5684814453125, 720.0]}]\n",
      "Frame 2830: [{'class': 'car', 'confidence': 0.8127615451812744, 'coordinates': [281.39990234375, 0.0, 649.799560546875, 720.0]}]\n",
      "Frame 2840: [{'class': 'car', 'confidence': 0.8589310050010681, 'coordinates': [280.5604248046875, 0.0, 668.6326904296875, 720.0]}]\n",
      "Frame 2850: [{'class': 'car', 'confidence': 0.8924469947814941, 'coordinates': [280.225830078125, 0.0, 788.73876953125, 720.0]}]\n",
      "Frame 2860: [{'class': 'car', 'confidence': 0.8508781790733337, 'coordinates': [280.1326904296875, 0.0, 851.7275390625, 720.0]}]\n",
      "Frame 2870: [{'class': 'car', 'confidence': 0.7843315005302429, 'coordinates': [279.6263427734375, 0.18853759765625, 975.0340576171875, 720.0]}]\n",
      "Frame 2880: [{'class': 'car', 'confidence': 0.7517893314361572, 'coordinates': [279.957763671875, 0.0, 987.822998046875, 720.0]}]\n",
      "Frame 2890: [{'class': 'car', 'confidence': 0.7905510067939758, 'coordinates': [280.2603759765625, 0.29168701171875, 1000.527099609375, 720.0]}]\n",
      "Frame 2900: [{'class': 'car', 'confidence': 0.7396656274795532, 'coordinates': [279.8391418457031, 0.0, 1000.302734375, 714.0596313476562]}]\n",
      "Frame 2910: [{'class': 'car', 'confidence': 0.7473823428153992, 'coordinates': [279.5103454589844, 0.0, 999.6795654296875, 717.8512573242188]}]\n",
      "Frame 2920: []\n",
      "Frame 2930: []\n",
      "Frame 2940: [{'class': 'car', 'confidence': 0.5701261162757874, 'coordinates': [915.2582397460938, 23.256114959716797, 983.9970092773438, 67.25495910644531]}, {'class': 'car', 'confidence': 0.3019205331802368, 'coordinates': [627.737548828125, 575.947998046875, 670.4306640625, 609.012451171875]}]\n",
      "Frame 2950: [{'class': 'car', 'confidence': 0.5638118982315063, 'coordinates': [915.2612915039062, 23.264827728271484, 983.9810180664062, 67.24588012695312]}, {'class': 'car', 'confidence': 0.45153459906578064, 'coordinates': [629.286376953125, 575.0557250976562, 675.832275390625, 612.5234985351562]}, {'class': 'car', 'confidence': 0.3616181015968323, 'coordinates': [538.3331298828125, 574.7066650390625, 580.8006591796875, 608.7703857421875]}]\n",
      "Frame 2960: [{'class': 'car', 'confidence': 0.5358665585517883, 'coordinates': [915.2576904296875, 23.267608642578125, 983.9498291015625, 67.25961303710938]}, {'class': 'car', 'confidence': 0.2914239764213562, 'coordinates': [627.5208740234375, 574.9271240234375, 682.3438720703125, 618.71533203125]}]\n",
      "Frame 2970: [{'class': 'car', 'confidence': 0.544916570186615, 'coordinates': [915.2943115234375, 23.281475067138672, 983.9796142578125, 67.34141540527344]}, {'class': 'car', 'confidence': 0.2956821322441101, 'coordinates': [624.6755981445312, 574.3294677734375, 686.0592651367188, 629.1422119140625]}, {'class': 'car', 'confidence': 0.26484641432762146, 'coordinates': [553.439208984375, 576.5711669921875, 588.309814453125, 602.7376708984375]}]\n",
      "Frame 2980: [{'class': 'car', 'confidence': 0.5856610536575317, 'coordinates': [915.2413940429688, 23.26117706298828, 984.0105590820312, 67.40018463134766]}, {'class': 'car', 'confidence': 0.25778642296791077, 'coordinates': [558.731689453125, 575.1243286132812, 592.124267578125, 601.1472778320312]}]\n",
      "Frame 2990: [{'class': 'car', 'confidence': 0.5905424356460571, 'coordinates': [915.2208251953125, 23.24047088623047, 984.0308837890625, 67.38079071044922]}]\n",
      "Frame 3000: [{'class': 'car', 'confidence': 0.6007447838783264, 'coordinates': [915.2593994140625, 23.26358413696289, 984.0355224609375, 67.3931884765625]}, {'class': 'car', 'confidence': 0.5808262228965759, 'coordinates': [590.256591796875, 572.0009765625, 676.039794921875, 636.9068603515625]}, {'class': 'car', 'confidence': 0.3559025526046753, 'coordinates': [932.481201171875, 587.0960083007812, 998.96044921875, 657.5272827148438]}]\n",
      "Frame 3010: [{'class': 'car', 'confidence': 0.6027481555938721, 'coordinates': [915.251220703125, 23.276771545410156, 983.99951171875, 67.3529281616211]}, {'class': 'car', 'confidence': 0.5338654518127441, 'coordinates': [899.3201293945312, 580.3560791015625, 999.6734008789062, 652.1558837890625]}, {'class': 'car', 'confidence': 0.4314735233783722, 'coordinates': [568.9400024414062, 569.9820556640625, 670.7723999023438, 642.0460205078125]}]\n",
      "Frame 3020: [{'class': 'car', 'confidence': 0.5630112290382385, 'coordinates': [915.2554931640625, 23.34705352783203, 984.0032958984375, 67.42781829833984]}, {'class': 'car', 'confidence': 0.37441200017929077, 'coordinates': [863.721435546875, 577.272216796875, 997.7431640625, 648.6190185546875]}, {'class': 'car', 'confidence': 0.2679321765899658, 'coordinates': [550.4498901367188, 569.7713012695312, 664.8881225585938, 653.6712036132812]}]\n",
      "Frame 3030: [{'class': 'car', 'confidence': 0.522869348526001, 'coordinates': [915.25634765625, 23.33991241455078, 983.928466796875, 67.33379364013672]}]\n",
      "Frame 3040: [{'class': 'car', 'confidence': 0.5919957756996155, 'coordinates': [868.471435546875, 559.32763671875, 999.4765625, 709.783447265625]}, {'class': 'car', 'confidence': 0.483206182718277, 'coordinates': [914.9879150390625, 23.376201629638672, 983.930908203125, 67.37168884277344]}, {'class': 'car', 'confidence': 0.42025914788246155, 'coordinates': [819.2874755859375, 584.9700927734375, 901.5386962890625, 635.8543701171875]}]\n",
      "Frame 3050: [{'class': 'car', 'confidence': 0.4875175952911377, 'coordinates': [915.3435668945312, 23.340621948242188, 983.9061889648438, 67.37376403808594]}, {'class': 'car', 'confidence': 0.47336697578430176, 'coordinates': [817.717529296875, 565.9347534179688, 999.4931640625, 705.6371459960938]}, {'class': 'car', 'confidence': 0.3653571605682373, 'coordinates': [501.24188232421875, 563.1453857421875, 665.6024780273438, 691.1900634765625]}]\n",
      "Frame 3060: [{'class': 'car', 'confidence': 0.6950181126594543, 'coordinates': [486.96527099609375, 561.6400146484375, 669.6068725585938, 697.3629150390625]}, {'class': 'car', 'confidence': 0.5166180729866028, 'coordinates': [915.31640625, 23.378643035888672, 983.90966796875, 67.37373352050781]}, {'class': 'car', 'confidence': 0.42895227670669556, 'coordinates': [785.383544921875, 572.4158935546875, 999.29541015625, 707.6055908203125]}]\n",
      "Frame 3070: [{'class': 'car', 'confidence': 0.7092174291610718, 'coordinates': [758.868896484375, 574.7703857421875, 992.003173828125, 700.2933349609375]}, {'class': 'car', 'confidence': 0.621794581413269, 'coordinates': [470.57568359375, 558.8381958007812, 671.9949951171875, 698.8045043945312]}, {'class': 'car', 'confidence': 0.5255445241928101, 'coordinates': [915.32763671875, 23.389415740966797, 983.89990234375, 67.38700866699219]}]\n",
      "Frame 3080: [{'class': 'car', 'confidence': 0.639372706413269, 'coordinates': [734.6988525390625, 575.2279663085938, 927.7279052734375, 683.9481811523438]}, {'class': 'car', 'confidence': 0.5896219611167908, 'coordinates': [451.537109375, 556.7469482421875, 675.68603515625, 702.6837158203125]}, {'class': 'car', 'confidence': 0.5347135663032532, 'coordinates': [915.3291015625, 23.38433074951172, 983.902099609375, 67.3731918334961]}]\n",
      "Frame 3090: [{'class': 'car', 'confidence': 0.6923351287841797, 'coordinates': [716.94970703125, 576.2999267578125, 884.188720703125, 674.218994140625]}, {'class': 'car', 'confidence': 0.6105285286903381, 'coordinates': [433.996826171875, 555.4669189453125, 675.1417236328125, 705.1990966796875]}, {'class': 'car', 'confidence': 0.5198591351509094, 'coordinates': [915.32275390625, 23.381729125976562, 983.905029296875, 67.41136169433594]}, {'class': 'car', 'confidence': 0.25789737701416016, 'coordinates': [341.47528076171875, 555.1893310546875, 432.60772705078125, 594.5404052734375]}]\n",
      "Frame 3100: [{'class': 'car', 'confidence': 0.6235893368721008, 'coordinates': [421.13800048828125, 554.4736938476562, 669.6047973632812, 695.8192749023438]}, {'class': 'car', 'confidence': 0.5352099537849426, 'coordinates': [915.3045654296875, 23.362091064453125, 983.920654296875, 67.36160278320312]}, {'class': 'car', 'confidence': 0.5244907736778259, 'coordinates': [699.040771484375, 576.2115478515625, 841.0308837890625, 662.5836181640625]}, {'class': 'car', 'confidence': 0.31802165508270264, 'coordinates': [851.8836059570312, 582.0413818359375, 894.6466674804688, 606.336181640625]}]\n",
      "Frame 3110: [{'class': 'car', 'confidence': 0.6053999662399292, 'coordinates': [915.1346435546875, 23.36560821533203, 983.9693603515625, 67.31702423095703]}, {'class': 'car', 'confidence': 0.49467870593070984, 'coordinates': [406.5362548828125, 551.509033203125, 658.7396240234375, 697.410888671875]}, {'class': 'car', 'confidence': 0.4905512034893036, 'coordinates': [682.2244873046875, 580.1796875, 802.6204833984375, 654.407470703125]}]\n",
      "Frame 3120: [{'class': 'car', 'confidence': 0.6377502083778381, 'coordinates': [395.92694091796875, 549.0031127929688, 650.6361694335938, 696.8593139648438]}, {'class': 'car', 'confidence': 0.5806063413619995, 'coordinates': [915.17626953125, 23.386005401611328, 983.979248046875, 67.28135681152344]}, {'class': 'car', 'confidence': 0.5379275679588318, 'coordinates': [672.7498779296875, 579.9299926757812, 776.7371826171875, 646.7405395507812]}]\n",
      "Frame 3130: [{'class': 'car', 'confidence': 0.6943660378456116, 'coordinates': [379.28436279296875, 549.33984375, 634.8314208984375, 698.21337890625]}, {'class': 'car', 'confidence': 0.6249459981918335, 'coordinates': [915.1838989257812, 23.32083511352539, 983.9472045898438, 67.37240600585938]}, {'class': 'car', 'confidence': 0.5261340141296387, 'coordinates': [660.4898071289062, 580.6124267578125, 752.2745971679688, 641.95703125]}]\n",
      "Frame 3140: [{'class': 'car', 'confidence': 0.7171981930732727, 'coordinates': [361.14544677734375, 546.477783203125, 615.0367431640625, 694.8388671875]}, {'class': 'car', 'confidence': 0.6333084106445312, 'coordinates': [915.1693115234375, 23.21847152709961, 983.9005126953125, 67.3924560546875]}, {'class': 'car', 'confidence': 0.4175848066806793, 'coordinates': [648.5015869140625, 579.9410400390625, 727.4586181640625, 633.7877197265625]}]\n",
      "Frame 3150: [{'class': 'car', 'confidence': 0.6879045963287354, 'coordinates': [358.85479736328125, 548.75439453125, 617.6390380859375, 696.53125]}, {'class': 'car', 'confidence': 0.6360054612159729, 'coordinates': [915.1591796875, 23.224884033203125, 983.89599609375, 67.39289855957031]}, {'class': 'car', 'confidence': 0.39573565125465393, 'coordinates': [636.4373779296875, 579.0203857421875, 709.363525390625, 628.8133544921875]}]\n",
      "Frame 3160: [{'class': 'car', 'confidence': 0.6551841497421265, 'coordinates': [915.5531005859375, 23.23221206665039, 983.764404296875, 67.08938598632812]}]\n",
      "Frame 3170: [{'class': 'car', 'confidence': 0.6600822806358337, 'coordinates': [915.59521484375, 23.19806671142578, 983.72509765625, 66.98468780517578]}, {'class': 'car', 'confidence': 0.42232877016067505, 'coordinates': [423.03533935546875, 545.7147216796875, 668.4285278320312, 688.6900634765625]}]\n",
      "Frame 3180: [{'class': 'car', 'confidence': 0.6186164021492004, 'coordinates': [915.64306640625, 23.213634490966797, 983.7010498046875, 66.95033264160156]}, {'class': 'car', 'confidence': 0.3837125897407532, 'coordinates': [426.6083984375, 548.2911376953125, 679.4619140625, 702.3057861328125]}]\n",
      "Frame 3190: [{'class': 'car', 'confidence': 0.6158033609390259, 'coordinates': [915.6373901367188, 23.230209350585938, 983.6889038085938, 66.98262023925781]}, {'class': 'car', 'confidence': 0.4129513204097748, 'coordinates': [427.74652099609375, 548.8597412109375, 688.9263305664062, 702.9820556640625]}]\n",
      "Frame 3200: [{'class': 'car', 'confidence': 0.5796836614608765, 'coordinates': [915.44482421875, 23.156326293945312, 983.9130859375, 67.36906433105469]}]\n",
      "Frame 3210: [{'class': 'car', 'confidence': 0.6194738149642944, 'coordinates': [915.4552612304688, 23.240840911865234, 983.7835083007812, 67.18051147460938]}]\n",
      "Frame 3220: [{'class': 'car', 'confidence': 0.6018481850624084, 'coordinates': [915.3232421875, 23.227848052978516, 983.9117431640625, 67.35934448242188]}]\n",
      "Frame 3230: [{'class': 'car', 'confidence': 0.597108781337738, 'coordinates': [915.095458984375, 23.095012664794922, 983.584716796875, 67.28804016113281]}, {'class': 'car', 'confidence': 0.30171534419059753, 'coordinates': [406.4057922363281, 541.9039306640625, 666.89990234375, 705.46240234375]}]\n",
      "Frame 3240: [{'class': 'car', 'confidence': 0.6501354575157166, 'coordinates': [915.2312622070312, 22.95850372314453, 983.5598754882812, 66.95203399658203]}]\n",
      "Frame 3250: []\n",
      "Frame 3260: []\n",
      "Frame 3270: [{'class': 'car', 'confidence': 0.4727272391319275, 'coordinates': [280.6890869140625, 242.08749389648438, 386.16748046875, 384.3727722167969]}, {'class': 'car', 'confidence': 0.4716717302799225, 'coordinates': [373.6890869140625, 135.20098876953125, 1001.8399658203125, 639.0464477539062]}]\n",
      "Frame 3280: [{'class': 'car', 'confidence': 0.43896836042404175, 'coordinates': [280.509033203125, 244.5927734375, 377.13531494140625, 386.43267822265625]}, {'class': 'car', 'confidence': 0.42643100023269653, 'coordinates': [365.66436767578125, 136.6094970703125, 1000.5256958007812, 637.9281616210938]}]\n",
      "Frame 3290: [{'class': 'car', 'confidence': 0.5590044260025024, 'coordinates': [280.4246826171875, 245.76666259765625, 362.791748046875, 387.88983154296875]}, {'class': 'car', 'confidence': 0.481773316860199, 'coordinates': [351.5547790527344, 136.57965087890625, 1000.0311279296875, 640.78173828125]}]\n",
      "Frame 3300: [{'class': 'car', 'confidence': 0.6352989077568054, 'coordinates': [280.22503662109375, 248.760986328125, 349.06964111328125, 388.8392333984375]}, {'class': 'car', 'confidence': 0.6352076530456543, 'coordinates': [340.0437316894531, 140.31976318359375, 1001.348388671875, 643.168212890625]}]\n",
      "Frame 3310: [{'class': 'car', 'confidence': 0.6846357583999634, 'coordinates': [327.8463134765625, 144.2884063720703, 1000.9222412109375, 646.7704467773438]}, {'class': 'car', 'confidence': 0.6155914664268494, 'coordinates': [280.5180969238281, 253.88125610351562, 340.2328796386719, 389.7176208496094]}]\n",
      "Frame 3320: [{'class': 'car', 'confidence': 0.6240816712379456, 'coordinates': [326.07781982421875, 147.0631103515625, 1000.6000366210938, 645.6666259765625]}, {'class': 'car', 'confidence': 0.6055610179901123, 'coordinates': [280.39349365234375, 256.5289306640625, 338.5218505859375, 392.74322509765625]}]\n",
      "Frame 3330: [{'class': 'car', 'confidence': 0.6671836376190186, 'coordinates': [324.309326171875, 147.16748046875, 1000.3565673828125, 647.137939453125]}, {'class': 'car', 'confidence': 0.6163548231124878, 'coordinates': [280.426025390625, 257.2122802734375, 334.2869873046875, 392.1954345703125]}]\n",
      "Frame 3340: [{'class': 'car', 'confidence': 0.6098951697349548, 'coordinates': [320.451416015625, 148.134521484375, 1001.2109375, 648.5993041992188]}, {'class': 'car', 'confidence': 0.568446934223175, 'coordinates': [280.3021545410156, 259.88470458984375, 331.1750183105469, 393.79376220703125]}]\n",
      "Frame 3350: [{'class': 'car', 'confidence': 0.6199946999549866, 'coordinates': [316.3209228515625, 148.46034240722656, 1000.888671875, 650.004638671875]}, {'class': 'car', 'confidence': 0.523820698261261, 'coordinates': [280.162353515625, 260.82672119140625, 325.2059326171875, 394.32427978515625]}]\n",
      "Frame 3360: [{'class': 'car', 'confidence': 0.5919932126998901, 'coordinates': [315.4042053222656, 149.41461181640625, 1001.6590576171875, 657.92041015625]}, {'class': 'car', 'confidence': 0.3393619954586029, 'coordinates': [280.3133239746094, 263.0352783203125, 326.6717224121094, 392.2547607421875]}]\n",
      "Frame 3370: [{'class': 'car', 'confidence': 0.6370078325271606, 'coordinates': [316.5706481933594, 149.03424072265625, 1001.3917236328125, 650.4926147460938]}, {'class': 'car', 'confidence': 0.41995182633399963, 'coordinates': [280.2906494140625, 263.0393981933594, 326.09051513671875, 391.6095275878906]}]\n",
      "Frame 3380: [{'class': 'car', 'confidence': 0.5598595142364502, 'coordinates': [316.0567932128906, 150.76011657714844, 1001.6805419921875, 648.67138671875]}]\n",
      "Frame 3390: [{'class': 'car', 'confidence': 0.8042712807655334, 'coordinates': [311.4140930175781, 149.177001953125, 1000.4560546875, 644.6136474609375]}, {'class': 'car', 'confidence': 0.4217127561569214, 'coordinates': [280.1953125, 264.64337158203125, 321.545654296875, 394.63629150390625]}]\n",
      "Frame 3400: [{'class': 'car', 'confidence': 0.7344179749488831, 'coordinates': [309.4728698730469, 150.28863525390625, 999.744384765625, 643.836669921875]}, {'class': 'car', 'confidence': 0.4000380039215088, 'coordinates': [280.03594970703125, 264.33453369140625, 324.29730224609375, 395.68902587890625]}]\n",
      "Frame 3410: [{'class': 'car', 'confidence': 0.6869195699691772, 'coordinates': [310.316162109375, 157.14385986328125, 996.6094970703125, 646.1512451171875]}, {'class': 'car', 'confidence': 0.516028642654419, 'coordinates': [280.16339111328125, 268.39227294921875, 320.97076416015625, 397.87310791015625]}]\n",
      "Frame 3420: [{'class': 'car', 'confidence': 0.5617440938949585, 'coordinates': [313.9212951660156, 160.71302795410156, 1000.0301513671875, 659.1954345703125]}, {'class': 'car', 'confidence': 0.44513261318206787, 'coordinates': [280.66815185546875, 270.571533203125, 346.98663330078125, 405.16571044921875]}]\n",
      "Frame 3430: [{'class': 'car', 'confidence': 0.5685437917709351, 'coordinates': [316.6302490234375, 160.54046630859375, 1000.9703369140625, 655.6258544921875]}, {'class': 'car', 'confidence': 0.4492267668247223, 'coordinates': [280.3977966308594, 270.92498779296875, 330.2375793457031, 401.2186279296875]}]\n",
      "Frame 3440: []\n",
      "Frame 3450: []\n",
      "Frame 3460: [{'class': 'car', 'confidence': 0.8935767412185669, 'coordinates': [280.7234802246094, 149.3289794921875, 1000.8262939453125, 591.7486572265625]}]\n",
      "Frame 3470: [{'class': 'car', 'confidence': 0.8661377429962158, 'coordinates': [279.968994140625, 160.42864990234375, 1001.393310546875, 628.977783203125]}]\n",
      "Frame 3480: [{'class': 'car', 'confidence': 0.8712794780731201, 'coordinates': [281.2957763671875, 168.3310546875, 992.6456298828125, 674.5039672851562]}, {'class': 'car', 'confidence': 0.6918845772743225, 'coordinates': [769.14501953125, 213.6040496826172, 999.677734375, 330.99102783203125]}]\n",
      "Frame 3490: [{'class': 'car', 'confidence': 0.8685010671615601, 'coordinates': [280.5460510253906, 154.7176513671875, 977.8995361328125, 708.6571044921875]}]\n",
      "Frame 3500: [{'class': 'car', 'confidence': 0.850094735622406, 'coordinates': [281.10174560546875, 129.17767333984375, 1000.2979125976562, 720.0]}]\n",
      "Frame 3510: [{'class': 'car', 'confidence': 0.854198157787323, 'coordinates': [281.57049560546875, 96.13800048828125, 1000.4808959960938, 720.0]}]\n",
      "Frame 3520: [{'class': 'car', 'confidence': 0.8601052165031433, 'coordinates': [280.720703125, 93.62908935546875, 1000.9149169921875, 720.0]}]\n",
      "Frame 3530: [{'class': 'car', 'confidence': 0.7982013821601868, 'coordinates': [279.1318054199219, 87.42510986328125, 999.880126953125, 720.0]}]\n",
      "Frame 3540: [{'class': 'car', 'confidence': 0.8060017824172974, 'coordinates': [280.31939697265625, 74.74700927734375, 1000.9413452148438, 720.0]}]\n",
      "Frame 3550: [{'class': 'car', 'confidence': 0.6884604096412659, 'coordinates': [277.5480651855469, 46.1807861328125, 999.726806640625, 720.0]}]\n",
      "Frame 3560: [{'class': 'car', 'confidence': 0.7627407312393188, 'coordinates': [319.533203125, 8.35174560546875, 999.8507080078125, 720.0]}]\n",
      "Frame 3570: [{'class': 'car', 'confidence': 0.8468379378318787, 'coordinates': [281.36322021484375, 3.265380859375, 999.5197143554688, 680.45556640625]}]\n",
      "Frame 3580: [{'class': 'car', 'confidence': 0.8208871483802795, 'coordinates': [279.9701843261719, 69.2471923828125, 999.9501953125, 672.1046142578125]}]\n",
      "Frame 3590: [{'class': 'car', 'confidence': 0.6935104131698608, 'coordinates': [280.008056640625, 150.6129150390625, 999.7637939453125, 712.7401123046875]}]\n",
      "Frame 3600: [{'class': 'car', 'confidence': 0.7943799495697021, 'coordinates': [279.267578125, 149.87957763671875, 1001.0264892578125, 665.8731689453125]}]\n",
      "Frame 3610: [{'class': 'car', 'confidence': 0.8246721625328064, 'coordinates': [393.880615234375, 157.79132080078125, 1002.0845947265625, 648.3798217773438]}]\n",
      "Frame 3620: [{'class': 'car', 'confidence': 0.5234251618385315, 'coordinates': [285.4019775390625, 268.18212890625, 974.275390625, 719.3131103515625]}, {'class': 'car', 'confidence': 0.26156994700431824, 'coordinates': [660.65087890625, 374.0394287109375, 999.837158203125, 717.95068359375]}]\n",
      "Frame 3630: [{'class': 'car', 'confidence': 0.7672259211540222, 'coordinates': [285.5451354980469, 289.518310546875, 960.4140625, 704.592041015625]}]\n",
      "Frame 3640: [{'class': 'car', 'confidence': 0.7971386909484863, 'coordinates': [360.79345703125, 300.5587463378906, 982.836669921875, 697.2977294921875]}, {'class': 'car', 'confidence': 0.34532490372657776, 'coordinates': [280.457763671875, 429.15179443359375, 314.798583984375, 519.2001342773438]}]\n",
      "Frame 3650: []\n",
      "Frame 3660: []\n",
      "Frame 3670: [{'class': 'car', 'confidence': 0.43811458349227905, 'coordinates': [515.6822509765625, 63.274986267089844, 933.894775390625, 317.4852600097656]}]\n",
      "Frame 3680: [{'class': 'car', 'confidence': 0.9079978466033936, 'coordinates': [341.8085632324219, 97.91015625, 803.918212890625, 363.38348388671875]}]\n",
      "Frame 3690: [{'class': 'car', 'confidence': 0.789361834526062, 'coordinates': [307.29425048828125, 3.8431396484375, 850.2647094726562, 296.0439453125]}]\n",
      "Frame 3700: [{'class': 'car', 'confidence': 0.265288382768631, 'coordinates': [303.0314636230469, 0.0, 928.87353515625, 274.696533203125]}]\n",
      "Frame 3710: []\n",
      "Frame 3720: []\n",
      "Frame 3730: []\n",
      "Frame 3740: [{'class': 'car', 'confidence': 0.5308260321617126, 'coordinates': [279.7344665527344, 176.51251220703125, 1000.3736572265625, 720.0]}]\n",
      "Frame 3750: [{'class': 'car', 'confidence': 0.9011834263801575, 'coordinates': [281.0863342285156, 0.71221923828125, 1000.0406494140625, 409.64642333984375]}, {'class': 'car', 'confidence': 0.4691943824291229, 'coordinates': [280.5111389160156, 261.2767639160156, 962.7137451171875, 720.0]}]\n",
      "Frame 3760: [{'class': 'car', 'confidence': 0.8227093815803528, 'coordinates': [280.48907470703125, 31.700347900390625, 1000.5084838867188, 455.0889587402344]}, {'class': 'car', 'confidence': 0.29374802112579346, 'coordinates': [281.0936584472656, 380.64990234375, 908.4473876953125, 720.0]}]\n",
      "Frame 3770: [{'class': 'car', 'confidence': 0.9070828557014465, 'coordinates': [280.2767333984375, 18.6610107421875, 1000.43701171875, 442.0533142089844]}, {'class': 'car', 'confidence': 0.2707994878292084, 'coordinates': [281.1717529296875, 395.27947998046875, 901.1495361328125, 720.0]}]\n",
      "Frame 3780: [{'class': 'car', 'confidence': 0.8956726789474487, 'coordinates': [281.0731201171875, 0.0159912109375, 988.5765380859375, 414.517822265625]}, {'class': 'car', 'confidence': 0.39098140597343445, 'coordinates': [280.4772033691406, 414.27728271484375, 896.4532470703125, 720.0]}]\n",
      "Frame 3790: [{'class': 'car', 'confidence': 0.8819250464439392, 'coordinates': [280.6113586425781, 0.0, 915.932373046875, 387.53070068359375]}, {'class': 'car', 'confidence': 0.4893192946910858, 'coordinates': [280.2049560546875, 396.8077392578125, 826.62744140625, 720.0]}]\n",
      "Frame 3800: [{'class': 'car', 'confidence': 0.8658434152603149, 'coordinates': [280.4305419921875, 0.0, 957.115234375, 380.979248046875]}, {'class': 'car', 'confidence': 0.3879973292350769, 'coordinates': [279.7093505859375, 394.1678771972656, 878.0081787109375, 720.0]}]\n",
      "Frame 3810: [{'class': 'car', 'confidence': 0.8656136989593506, 'coordinates': [280.5947265625, 0.0, 951.3140869140625, 371.698486328125]}, {'class': 'car', 'confidence': 0.5215449333190918, 'coordinates': [280.61102294921875, 412.429931640625, 796.5242309570312, 720.0]}]\n",
      "Frame 3820: [{'class': 'car', 'confidence': 0.8778936862945557, 'coordinates': [280.3253173828125, 0.0, 950.22802734375, 370.2633972167969]}, {'class': 'car', 'confidence': 0.4100305438041687, 'coordinates': [281.2752685546875, 452.9787902832031, 749.5836181640625, 720.0]}]\n",
      "Frame 3830: [{'class': 'car', 'confidence': 0.856870174407959, 'coordinates': [280.477783203125, 0.0, 953.8875732421875, 369.8612365722656]}, {'class': 'car', 'confidence': 0.5725911259651184, 'coordinates': [281.3341064453125, 492.02392578125, 662.5736694335938, 720.0]}]\n",
      "Frame 3840: [{'class': 'car', 'confidence': 0.8223810195922852, 'coordinates': [279.4745788574219, 14.651763916015625, 962.099365234375, 383.0041809082031]}, {'class': 'car', 'confidence': 0.5538875460624695, 'coordinates': [280.41265869140625, 520.743896484375, 662.7001953125, 720.0]}]\n",
      "Frame 3850: [{'class': 'car', 'confidence': 0.8631213307380676, 'coordinates': [281.6056823730469, 39.80621337890625, 1000.54541015625, 415.2539367675781]}, {'class': 'car', 'confidence': 0.33524200320243835, 'coordinates': [280.24530029296875, 539.4464111328125, 658.0712890625, 720.0]}]\n",
      "Frame 3860: [{'class': 'car', 'confidence': 0.8383631706237793, 'coordinates': [291.4099426269531, 23.780517578125, 1000.185791015625, 414.8466796875]}]\n",
      "Frame 3870: [{'class': 'car', 'confidence': 0.8681995868682861, 'coordinates': [279.62139892578125, 0.032196044921875, 1000.6469116210938, 390.12353515625]}, {'class': 'car', 'confidence': 0.44690999388694763, 'coordinates': [280.808837890625, 422.14227294921875, 851.003662109375, 720.0]}]\n",
      "Frame 3880: [{'class': 'car', 'confidence': 0.8958657383918762, 'coordinates': [280.81097412109375, 0.0, 1000.3123168945312, 410.3458251953125]}, {'class': 'car', 'confidence': 0.452929824590683, 'coordinates': [281.1695861816406, 467.9329833984375, 839.8494873046875, 720.0]}]\n",
      "Frame 3890: [{'class': 'car', 'confidence': 0.9024289846420288, 'coordinates': [280.95159912109375, 0.0, 1000.7874145507812, 422.45440673828125]}, {'class': 'car', 'confidence': 0.3671514689922333, 'coordinates': [280.102294921875, 478.92718505859375, 781.4747314453125, 720.0]}]\n",
      "Frame 3900: [{'class': 'car', 'confidence': 0.8201680183410645, 'coordinates': [281.0843505859375, 0.0, 1001.880859375, 377.40911865234375]}, {'class': 'car', 'confidence': 0.570690929889679, 'coordinates': [280.057861328125, 291.982177734375, 839.4869384765625, 720.0]}]\n",
      "Frame 3910: [{'class': 'car', 'confidence': 0.5122148394584656, 'coordinates': [280.7846984863281, 0.0, 948.045654296875, 357.5712890625]}, {'class': 'car', 'confidence': 0.5065925717353821, 'coordinates': [279.92352294921875, 230.6300048828125, 853.5719604492188, 720.0]}, {'class': 'plane', 'confidence': 0.30596643686294556, 'coordinates': [279.7125244140625, 0.0, 948.2308349609375, 360.22900390625]}]\n",
      "Frame 3920: [{'class': 'car', 'confidence': 0.5805487632751465, 'coordinates': [281.3126220703125, 0.1807861328125, 867.20361328125, 424.4190673828125]}]\n",
      "Frame 3930: [{'class': 'car', 'confidence': 0.6565881371498108, 'coordinates': [280.8963928222656, 0.597991943359375, 811.6998291015625, 455.7206726074219]}, {'class': 'car', 'confidence': 0.42631855607032776, 'coordinates': [280.2823486328125, 271.9668884277344, 1000.4549560546875, 720.0]}]\n",
      "Frame 3940: [{'class': 'car', 'confidence': 0.8898653984069824, 'coordinates': [279.59588623046875, 0.0, 1000.1578979492188, 535.1925659179688]}]\n",
      "Frame 3950: [{'class': 'car', 'confidence': 0.7218437194824219, 'coordinates': [279.95709228515625, 0.0, 1000.0270385742188, 567.9502563476562]}]\n",
      "Frame 3960: [{'class': 'car', 'confidence': 0.9147418141365051, 'coordinates': [280.3123474121094, 0.38055419921875, 999.9761962890625, 509.520751953125]}]\n",
      "Frame 3970: [{'class': 'car', 'confidence': 0.9358634948730469, 'coordinates': [280.91455078125, 0.44635009765625, 1000.5986328125, 520.0830688476562]}]\n",
      "Frame 3980: [{'class': 'car', 'confidence': 0.9236711859703064, 'coordinates': [280.009765625, 1.03289794921875, 1000.1236572265625, 543.0429077148438]}]\n",
      "Frame 3990: [{'class': 'car', 'confidence': 0.9328848719596863, 'coordinates': [280.52880859375, 0.0, 1000.1602783203125, 519.0108642578125]}]\n",
      "Frame 4000: [{'class': 'car', 'confidence': 0.9475860595703125, 'coordinates': [281.0628662109375, 0.706787109375, 996.201171875, 473.2515869140625]}]\n",
      "Frame 4010: [{'class': 'car', 'confidence': 0.9193775653839111, 'coordinates': [281.47039794921875, 0.114166259765625, 984.9168090820312, 461.4161071777344]}]\n",
      "Frame 4020: [{'class': 'car', 'confidence': 0.9484102725982666, 'coordinates': [281.8975830078125, 0.0, 968.80810546875, 470.61016845703125]}]\n",
      "Frame 4030: [{'class': 'car', 'confidence': 0.932495653629303, 'coordinates': [281.5692443847656, 0.0, 982.7720947265625, 466.7184143066406]}]\n",
      "Frame 4040: [{'class': 'car', 'confidence': 0.9133857488632202, 'coordinates': [282.0131530761719, 0.0, 996.996337890625, 428.9422607421875]}]\n",
      "Frame 4050: [{'class': 'car', 'confidence': 0.898511528968811, 'coordinates': [281.5372314453125, 0.922576904296875, 1001.1220703125, 401.2869567871094]}]\n",
      "Frame 4060: [{'class': 'car', 'confidence': 0.9125333428382874, 'coordinates': [281.60662841796875, 0.6658935546875, 1001.1515502929688, 394.33428955078125]}]\n",
      "Frame 4070: [{'class': 'car', 'confidence': 0.9204472899436951, 'coordinates': [281.5159912109375, 0.0, 987.4971923828125, 391.13922119140625]}]\n",
      "Frame 4080: [{'class': 'car', 'confidence': 0.8976137638092041, 'coordinates': [281.5726013183594, 0.952056884765625, 948.0301513671875, 375.5802001953125]}]\n",
      "Frame 4090: [{'class': 'car', 'confidence': 0.9038852453231812, 'coordinates': [281.294189453125, 0.761871337890625, 927.1761474609375, 361.2829895019531]}]\n",
      "Frame 4100: [{'class': 'car', 'confidence': 0.9296229481697083, 'coordinates': [281.967041015625, 0.0, 946.5560302734375, 407.375244140625]}]\n",
      "Frame 4110: [{'class': 'car', 'confidence': 0.926183819770813, 'coordinates': [280.9697265625, 0.0, 1000.8104248046875, 451.25103759765625]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x636aeee8d740] Invalid NAL unit size (3299 > 3009).\n",
      "[NULL @ 0x636aeee8d740] missing picture in access unit with size 3013\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x636af19cdb80] stream 1, offset 0xb6f1f2: partial file\n",
      "[h264 @ 0x636b11b26e40] Invalid NAL unit size (3299 > 3009).\n",
      "[h264 @ 0x636b11b26e40] Error splitting the input into NAL units.\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
